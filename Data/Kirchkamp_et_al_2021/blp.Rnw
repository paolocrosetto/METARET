\documentclass[12pt,a4paper]{scrartcl}
\scrollmode
\usepackage{array}
\usepackage[british]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsfonts}\allowdisplaybreaks
\usepackage[tt=false]{libertine}
\usepackage{manfnt}
\usepackage{eulervm}
\usepackage{eurosym}
\usepackage{tikz}\usetikzlibrary{shadows}
\renewcommand{\topfraction}{.7}
\renewcommand{\bottomfraction}{0.0}
\newtheorem{hypothesis}{Hypothesis}
\usepackage{natbib} % to use citet
\usepackage{xcolor}
% own macros:
\long\def\ok#1{{\color{blue}\itshape[[ok: #1]]}}
\def\hd#1{\emph{\color{red}#1}}
%%\def\ok#1{}
\def\task{k}
\def\prob{p}
\def\BLP{labBLP}
\def\other{\text{std}}
\def\otherLong{standard}
\def\labStd{otherStd}
\def\labBLP{labBLP}
\def\onlineStd{onlineStd}
\def\onlineBLP{onlineBLP}
\def\rank{\mathop{\text{rank}}}
\def\median{\mathop{\text{median}}}
\def\Rlow{\underline{R}}
\def\Rhigh{\overline{R}}
\def\blp{\text{BLP}}
\def\EGtask{\citet{eckel2002sex} task}
\def\HLtask{\citet{holt2002risk} task}
\def\EGshort{EG task}
\def\HLshort{HL task}
\def\LL{\mathop{\mathcal{L}}}
\def\Rchoice{{\text{risky}}}
\def\probcrit{\prob^c}
\def\Lott{\frak{L}}
\def\tauLi{\tau_{\Lott,i}}
\def\tauR{\tau_r}
\def\randomR{\tilde{r}}
\def\square{\fbox{\phantom{x}}}
\def\currentPaper{Current paper}
\def\normal{$\mu_r \sim N(0,.1)$}
\def\normalii{$\mu_r \sim N(.5,.1)$}
\def\robust{$r \sim t(\mu_r,\tauR,\nu)$}
\def\normal{M1}
\def\normalii{M2}
\def\robust{M3}
\def\randomPref{M4}
\def\CHANGE{\marginpar{\dbend}}
\usepackage{hyperref}
\begin{document}
<<init,include=FALSE,cache=FALSE>>=
 opts_chunk[["set"]](fig.path='figure/small-', cache.path='cache/small-', 
     fig.align='center', dev='tikz', external=FALSE, fig.width=4.5, 
     fig.height=3, fig.show='hold', size="footnotesize",echo=FALSE,warning=FALSE, 
     error=TRUE, message=TRUE, tidy=FALSE,cache=TRUE,autodep=TRUE, par=TRUE, comment=NA, keep.blank.line=FALSE)
 knit_hooks[["set"]](par=function(before, options, envir){
 if (before) { options(width=80) }
 if (before && options[["fig.show"]]!='none') par(mar=c(4,4,1,.1),cex.main=1,font.main=1,cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3)
 }, crop=hook_pdfcrop)
options(tikzMetricsDictionary="tikz.metrics")
options(scipen=9)
@ 
<<libs,echo=FALSE,include=FALSE,cache=FALSE>>=
readData<-TRUE ## set this to TRUE if you have (all) the raw data
                ## we include the raw data for some of the studies
                ## but we don't have permission to include it for all the studies
                ## below we provide all the commands one needs to prepare the data
                ## with these commands you can replicate the preparation of our data
                ## (if you get the raw data from the authors of the studies)
slow<-TRUE      ## set this to TRUE to calculate posteriors (this may take an hour or more)
if(length(list.files("mcmc","*.Rdata")) < 15) ## if you don't have these files you must calculate posteriors
    slow<-TRUE 
bootSize<-1000
library(xtable)
options(xtable.floating=FALSE)
options(xtable.sanitize.text.function=function(x) x)
library(haven)
library(runjags)
library(coda)
library(lattice)
library(latticeExtra)
library(plyr)
library(lme4)
library(stargazer)
library(binom)
library(boot)
library(zTree)
options(zTree.silent=TRUE)
library(readxl)
library(magrittr)
library(dplyr)
##
if(Sys.info()[["sysname"]]=='FreeBSD')
    runjags.options(jagspath='/usr/local/bin/mcmc-jags')
jagsVer<-testjags(silent=TRUE)
##
rjver<-sessionInfo()[["otherPkgs"]][["runjags"]][["Version"]]
lme4ver<-sessionInfo()[["otherPkgs"]][["lme4"]][["Version"]]
mTheme<-standard.theme("pdf", color=FALSE)
lattice.options(default.theme=mTheme)
##
runjags.options(silent.jags=FALSE,silent.runjags=FALSE,method="parallel",
                modules="glm",predraw.plots=FALSE)
initJags<-list()
initJags[[1]]<-list(.RNG.seed=1,.RNG.name="base::Mersenne-Twister")
initJags[[2]]<-list(.RNG.seed=2,.RNG.name="base::Super-Duper")
initJags[[3]]<-list(.RNG.seed=3,.RNG.name="base::Wichmann-Hill")
initJags[[4]]<-list(.RNG.seed=4,.RNG.name="lecuyer::RngStream")
##
odds <- function(x,mu=0) {
    o<-mean(x>mu)
    class(o)<-"odds"
    o
}
string.odds <- function (o) {
    if(o==1) return("40000:0");
    if(o==0) return("0:40000");
    or<-c(o/(1-o),1)
    paste(signif(or/min(or),3),collapse=":")
}
print.odds <- function (o) {
    cat(string.odds(o),"\n")
    o
}
int.odds <- function(o,stem="x is",text=c("larger","smaller"),Jeff=FALSE) {
    or<-o/(1-o)
    eType<-cut(abs(log10(or)),c(0,.5,1,1.5,2,Inf),c("only anecdotal","moderate","strong","very strong","decisive"))
    if(!Jeff) {
        eType<-cut(abs(log(or)),c(0,1,3,5,Inf),c("only anecdotal","positive","strong","very strong"))
    }
    paste("“",eType,"” evidence that ",stem," ",text[ifelse(or>1,1,2)],sep="")
}
@ 
<<typeBLPconversion>>=
## BLP should be rendered more nicely
typeT1 <- function(type) 
    factor(ifelse(grepl("online",type),type,
                       ifelse(type=="BLP","\\labBLP","\\labStd")))
typeT0 <- function(type,order=NULL) {
    x<-factor(ifelse(type=="BLP","\\labBLP",type))
    if(!is.null(order))
        x<-reorder(x,-grepl(order,x))
    x
}
@ 
%
\input rev.tex

<<literature>>=
Literature<-read.csv(sep=";",text='type;ref;ltype;exp
DOV;\\citet{dursch2012sick};HL;2011 
BHO;\\citet{brunner2014premium};HL;2011
RTV;\\citet{roth2016role};HL  aggr.;Feb, Mar 2012
DRR;\\citet{duersch2017intertemporal};HL aggr.;Sep 2012, Jan 2013
PRS;\\citet{proto2019teach};HL;Apr, Nov 2018
AOW;\\citet{apesteguia2018copy};EG // 4 choices;Jan, May, Jun, Jul, Aug 2017
LMK;\\citet{koenig2019active};EG // 11 choices [0..15€];Oct, Nov 2017
S;\\citet{schmidt2019focal};EG // 8 choices [0..10.5€];Jan, Feb 2018
BLP;\\currentPaper;EG+HL;Nov, Dec 2018
onlineBLP;\\currentPaper;EG+HL;Sep 2020
onlineStd;\\currentPaper;EG+HL;Sep 2020')
@ 
%
<<prepareDataPreparation>>=
EG.payoffs<-list()
EG.payoffs[["S"]]<-cbind(low=seq(4,.5,-.5),high=c(seq(4,10,1),10.5))
EG.payoffs[["BLP"]]      <-cbind(low=c(38,28,16,0),high=c(38,52,72,84)) ## prize: 5€ ##BLP.prizes<-c(40,32,77,2)
EG.payoffs[["onlineBLP"]]<-cbind(low=c(38,28,16,0),high=c(38,52,72,84)) ## prize: 5€ ##BLP.prizes<-c(40,32,77,2)
EG.payoffs[["onlineStd"]]<-cbind(low=c(38,28,16,0),high=c(38,52,72,84)) ## prize: 5€ ##BLP.prizes<-c(40,32,77,2)
EG.payoffs[["LMK"]]<-cbind(low=c(seq(6,1.2,-.6),.9,0),high=seq(6,15,.9))
EG.payoffs[["AOW"]]<-cbind(low=c(7.2,6.4,4,.8),high=c(8,15,18.6,20.8))
##
## for all EG procedures: interpret choice as preference:
EG.payoffs.all<-rbind.fill(lapply(names(EG.payoffs), 
                                  function(x) within(data.frame(EG.payoffs[[x]]),{
                                      type<-x
                                      expPay<-low+high
                                      choice<-1:length(low)
                                      maxPay<-max(expPay)
                                      neutral<-maxPay==expPay # risk neutral maximises expected payoffs
                                      averse<-median(high[neutral])>high # seem to interpret these lotteries reasonably
                                      pref<-ifelse(neutral,"neutral",ifelse(averse,"averse","riskSeeking"))
                                      })))[,c("low","high","pref","type","choice")]
##
HL.payoffs<-as.matrix(data.frame(highProb=1:10/10,low1=1.6,high1=2,low2=.1,high2=3.85))
switch2cchoice<-function(s) 1:10>=s ## s is the first switch to the risky lottery
choice2ind<-function(c) {
    if (is.na(c)) 
    { c(1,NA,NA,NA,NA) }
    else 
    { if(c) 1:5 else c(1,4,5,2,3) } 
    }
choice2lott <- function (choices) {
    xx<-within(adply(data.frame(i=1:10,c=choices),1,function(x) HL.payoffs[x$i,choice2ind(x$c)]),{
        i<-NULL
        c<-NULL})
    names(xx)[2:5]<-c("low","high","prefLow","prefHigh")
    subset(xx,!is.na(low))
    }
switch2lott <- function(s) ## s is the first switch to the risky lottery
    choice2lott(switch2cchoice(s))              
##
wide2lott <- function(df) {
    hl.names<-grep("^hl_",names(df),value=TRUE)
    x<-adply(df,1,function(x) choice2lott(unlist(x[1,hl.names])))
    x[,grep("^hl_",names(x),invert=TRUE)]
}
##
cleanWideHL <- function(df,code=c(0,1),type="unknownType",id="sid") {
    if(! id %in% names(df))
        stop("data contains no 'id' variable")
    df[["sid"]]<-paste(type,df[[id]],sep="-")
    df[["type"]]<-type
    df<-df[,grep("hl_|sid|session|gender|type|e_g",names(df),value=TRUE)]
    hl.names<-grep("hl_",names(df),value=TRUE)
    if(sum(! is.na(df[,hl.names]) & ! (unlist(df[,hl.names]) %in% code))>0)
        stop("data contains values other than those specified by 'code'")
    df[,hl.names]<-df[,hl.names]==code[2] ## code for risky choice
    df<-adply(df,1,function(risky) {
        minRisk <- min(c(which(risky[1,hl.names]==TRUE),length(hl.names)+1))
        maxSafe <- max(c(0,which(risky[1,hl.names]==FALSE)))
        undecided <- sum(is.na(risky[1,hl.names]))
        consistent<- maxSafe < minRisk &  undecided==0 & risky[1,"hl_10"]
        hlSwitch <- sum(! risky[1,hl.names],na.rm=TRUE)+1+undecided/2
        c(hlSwitch=hlSwitch,consistent=consistent)})
    df
}
#--------------------
## functions for EG:
egChoice2pairs<-function(x,pay=EG.payoffs) {
    xx<-data.frame(pay[-x$choice,])
    xx$prefLow<-pay[x$choice,1]
    xx$prefHigh<-pay[x$choice,2]
    xx$highProb<-.5
    xx
}
##
eg2lott <- function(df,pay) 
    adply(df,1,function(x) egChoice2pairs(x,pay=pay))[c("type","sid","low","high","prefLow","prefHigh","highProb")]
##
@ 
<<initLists>>=
HL<-list()
HLS<-list()
EG<-list()
Lott<-list()
@ 
<<DOV,eval=readData>>=
# --------------------    
## DOV,Dürsch et al. (2012),HL
HL[["DOV"]]<-cleanWideHL(read.csv("data/DOV/dov.csv"),type="DOV",code=1:0)
Lott[["DOV"]]<-wide2lott(HL[["DOV"]])
@ 
<<BHO.data,eval=readData>>=
## BHO,Brunner et al. (2014),HL ( 1 codes safe, 0 codes risky)
## we removed names and matriculation numbers from the original data
## xx<-read.csv("data/dataBHO.txt",sep="\t")
## write.table(xx[,grep("^d[1-9]|Session|ID",names(xx))],file="data/dataBHOanon.txt",sep="\t",row.names=FALSE,quote=FALSE)
xx<-read.csv("data/dataBHOanon.txt",sep="\t") 
## from the original data it is obvious that some participants participated twice
## this is, of course, not visible in the anonymised data. We remove the duplicates here:
xx<-subset(xx,! paste(Session,ID,sep="-") %in% c("5-19","5-30","5-15","5-24","6-29","6-30"))
##
bhoChoices<-grep("^d[0-9]*$",names(xx),value=TRUE)
for(n in bhoChoices)
    xx[,n]<-as.numeric(as.character(xx[,n]))
xx<-xx[apply(is.na(xx[,bhoChoices]),1,sum)<10,] ## drop empty sheets
names(xx)<-gsub("^d([0-9]*)$","hl_\\1",names(xx))
HL[["BHO"]]<-cleanWideHL(within(xx,sid<-sprintf("%d-%d",Session,ID)),type="BHO",code=1:0)
## remove empty sheets:
Lott[["BHO"]]<-wide2lott(HL[["BHO"]])
@ 
<<RTV,eval=readData,include=FALSE>>=
## RTV,Roth et al. (2016) ,HL (only consistent, only switch)
sheets<-excel_sheets("data/RTV_bysession.xlsx")
RTV.combined<-rbind.fill(lapply(sheets[grep("session",sheets)],function(s) 
    within(read_xlsx("data/RTV_bysession.xlsx",s),{
           session<-s
           type<-"RTV"
           consistent<-1})))
HLS[["RTV"]]<-within(RTV.combined,{
    sid<-paste(date,session,ifelse(is.na(Subject),Subject...5,Subject),sep="-")
    hlSwitch<-A_1_HL})[,c("type","sid","hlSwitch","consistent")]
Lott[["RTV"]]<-adply(HLS[["RTV"]],1,function(x) switch2lott(x$hlSwitch))
## Prices for lotteries are reported in the paper - Hurrah!!! (2.00/1.60-3.85,0.10€)
@ 
<<DRR,eval=readData>>=
## DRR,Dürsch et al. (2017),HL // (only switch) 10 choices aggr. why more? 
## missing platznummer for 35 observations
## missing switch for “consistent” observations
DRR.raw<-within(read_dta("data/DRR.dta"),{
    missingID<-sum(is.na(platznummer))
    platznummer[is.na(platznummer)]<-(1:missingID)+1000
    sid<-paste("DRR",session,platznummer,sep="-")
    type<-"DRR"})[,c("type","sid","hl1","hl1_inconsistent")]
ni<-sum(is.na(DRR.raw[["hl1_inconsistent"]]))
hlNA<-with(subset(DRR.raw,hl1_inconsistent==0),sum(is.na(hl1)))
if(hlNA>0) warning("There are ",hlNA," observations in DRR marked ``consistent'' where hl1 is missing. We drop them.")
if(ni>0) warning("There are ",ni," observations in DRR where ``inconsistent'' is missing.
We just treat them as consistent as far as possible.")
DRR.raw<-within(DRR.raw,hl1_inconsistent[is.na(hl1_inconsistent)]<-0) ## ... we just treat them as consistent
DRR.raw<-subset(DRR.raw,!is.na(hl1) | hl1_inconsistent) 
HLS[["DRR"]]<-within(DRR.raw,{
    hlSwitch <- hl1
    consistent <- 1 - hl1_inconsistent
    hl1_inconsistent <- NULL
    hl1 <- NULL})
Lott[["DRR"]]<-adply(subset(HLS[["DRR"]],consistent==1),
                1,function(x) switch2lott(x$hlSwitch))
@
<<PRS,eval=readData>>=
## Proto et al. (2019), H+L (safe=1, risky=2)
prs.fn<-dir("data/PRS/","*.xls",full.names=TRUE)
PRS.t<-zTreeTables(prs.fn,table="subjects",ignore.errors=TRUE)
PRS.1<-subset(PRS.t$subjects,!is.na(lottery1))[,c("Date","Treatment","Period","Subject",grep("^lottery",names(PRS.t$subjects),value=TRUE))]
names(PRS.1)<-sub("^lottery","hl_",names(PRS.1))
PRS.2<-within(PRS.1,sid<-paste(Date,Subject,sep="-"))
PRS.3<-PRS.2[,grep("hl_|sid|type",names(PRS.2),value=TRUE)]
HL[["PRS"]]<-cleanWideHL(PRS.3,type="PRS",code=1:2)
Lott[["PRS"]]<-wide2lott(HL[["PRS"]])
@ 
<<AOW,eval=readData>>=
## Apesteguia et al. (2018), E+G
aow.fn<-dir("data/AOW/","*.xls",full.names=TRUE)
AOW.t<-zTreeTables(aow.fn,table="subjects",ignore.errors=TRUE)
##   *** File data/AOW//170118_1042.xls contains empty cells in globals, subjects, [82,83]. This is not a z-Tree file *** 
EG[["AOW"]]<-within(subset(AOW.t$subjects,Treatment==1 & Period==1)[,c("Date","Subject","profitP1")],{
       sid<-paste("AOW",Date,Subject,sep="-")
       choice<-profitP1
       type<-"AOW"})[,c("type","sid","choice")]
Lott[["AOW"]]<-eg2lott(EG[["AOW"]],EG.payoffs[["AOW"]])
@ 
<<S.data,eval=readData,include=FALSE>>=
S<-read_xlsx("data/S.xlsx")[,1]
names(S)<-"choice"
EG[["S"]]<-within(S,{
          sid<-paste("S",1:nrow(S),sep="-")
          type<-"S"
          })
Lott[["S"]]<-eg2lott(EG[["S"]],EG.payoffs[["S"]])
@ 
<<BLP.data,eval=readData>>=
## (safe=1, risky=0)
blp.xlsx<-read_excel("data/blp.xlsx")
HL[["BLP"]]<-cleanWideHL(blp.xlsx,code=1:0,type="BLP",id="id")
Lott[["BLP.HL"]]<-wide2lott(HL[["BLP"]])
EG[["BLP"]]<-within(HL[["BLP"]],{
    choice<-e_g
    type<-"BLP"})[,c("type","sid","choice")]
Lott[["BLP"]]<-eg2lott(EG[["BLP"]],pay=EG.payoffs[["BLP"]])
@ 
<<LMK.data,eval=readData>>=
LMK.xlsx<-subset(read_xlsx("data/LMK/All_apps_-_wide_(accessed_2017-11-10).xlsx"),
                 !session.is_demo)[,c("participant.code","risktaking_lastpart.1.player.eg_choice","risktaking_lastpart.1.player.eg_payoff")]
names(LMK.xlsx)<-gsub("risktaking_lastpart.1.player.eg_|.code","",names(LMK.xlsx))
EG[["LMK"]]<-within(LMK.xlsx,{
    type<-"LMK"
    sid<-paste(type,participant,sep="-")})[,c("type","sid","choice")]
Lott[["LMK"]]<-eg2lott(EG[["LMK"]],EG.payoffs[["LMK"]])
@
<<BLP.online.data,eval=readData>>=
BLPraw<-subset(read.csv("data/blpOnline.csv"),!is.na(eg))
##remove personal data:
##write.csv(file="data/blpOnline.csv",BLPraw[,-grep("pseudo|iban|name|email|plz|city",names(BLPraw))])
names(BLPraw)<-gsub("hl","hl_",names(BLPraw))
##
onlineNames<-c("onlineStd","onlineBLP")
for (b in 0:1) {
    nn <- onlineNames[b+1]
    EG[[ nn ]]<-within(subset(BLPraw,blp==b),{
        type <- onlineNames[b+1]
        sid <- sprintf("%s-%03d",type,i)
        choice <- eg})[,c("type","sid","choice")]
    Lott[[ nn ]] <- eg2lott(EG[[ nn ]],pay=EG.payoffs[[ nn ]])
    ##
    HL[[ nn ]] <- cleanWideHL(subset(BLPraw, blp==b), type=nn, code=0:1, id="i")
    Lott[[ paste0(nn,".HL") ]] <- wide2lott(HL[[ nn ]])
}
@ 
<<createDirs>>=
if(!file.exists("mcmc"))
    dir.create("mcmc")
if(!file.exists("data"))
    dir.create("data")
@ 
<<saveData,eval=readData,cache=FALSE>>=
save(file="data/data.Rdata",HL,HLS,EG,Lott)
@ 
<<prepare>>=
load("data/data.Rdata")
HL.df<-rbind.fill(HL)
HLS.df<-rbind.fill(HLS)
HL.all<-rbind.fill(HL.df,HLS.df)
EG.df<-rbind.fill(EG)
@ 
%--------------------------------------------------------------------------------

\title{The Binary Lottery Procedure does not induce risk neutrality in the
Holt \& Laury and Eckel \& Grossman tasks\thanks{%
We would like to thank three anonymous referees, Glenn Harrison and Karim Sadrieh for valuable
comments. We use \Sexpr{jagsVer[["R.version"]]} for the empirical analysis. We use
\texttt{runjags} \Sexpr{rjver} to interface  with \texttt{JAGS \Sexpr{jagsVer[["JAGS.version"]]}}.
Funding for this study was provided by the University of Heidelberg.
}}
\author{Oliver Kirchkamp\thanks{University of Jena: email: oliver@kirchkamp.de}
  \and
  Joerg Oechssler\thanks{%
University of Heidelberg: email: oechssler@uni-hd.de} \and Andis Sofianos%
\thanks{%
University of Heidelberg: email: andis.sofianos@uni-heidelberg.de}}
\date{\GITAuthorDate\quad\texttt{\GITAbrHash}
}
\maketitle

\begin{abstract}
  \noindent We test whether the binary lottery procedure makes
  participants behave as if they are risk neutral in the
  \citet{holt2002risk} and \EGtask{}s.  Depending on the task, we find
  that less than half of the participants behave as if risk neutral. In
  fact, when we compare the distribution of choices, we find no
  significant difference to standard experiments that did not use the
  binary lottery procedure.
%
Using a structural model we find modest evidence that the binary
lottery procedure might move participants at least slightly towards risk
neutrality.
%

\noindent \textbf{Keywords:} risk elicitation, binary lottery procedure;
experimental economics.

\noindent\textbf{JEL-Classification:}C91; C81
\end{abstract}

\thispagestyle{empty} \newpage
<<textResults,cache=FALSE>>=
text.binomCI <- function (x) {
    z<-binom.confint(sum(x),length(x),methods="exact")
    list(mean=sprintf("%.2f\\%%",z[["mean"]]*100),
              ci95=sprintf("$CI_{95}$=[%.2f,\\penalty0 %.2f]",z[["lower"]]*100,z[["upper"]]*100))
}
##
nPartCompareLab <- sum(sapply(HL,nrow) + sapply(EG,nrow)) - sum(sapply(c("BLP","onlineBLP","onlineStd"),function(e) nrow(EG[[e]])+nrow(HL[[e]])))
#  
nsession<-length(unique(HL[["BLP"]][["session"]]))
nsessionOnline<-length(unique(HL[["onlineBLP"]][["session"]]))
inconsistentPart<-sum(HL[["BLP"]][["consistent"]]==0)
inconsistentOnline<-sum(HL[["onlineBLP"]][["consistent"]]==0)

##
egRN<-text.binomCI(EG[["BLP"]][["choice"]]==3)
egOnlineRN<-text.binomCI(EG[["onlineBLP"]][["choice"]]==3)
##
hlRN<-text.binomCI(subset(HL[["BLP"]],consistent==1)[["hlSwitch"]]==5)
hlOnlineRN<-text.binomCI(subset(HL[["onlineBLP"]],consistent==1)[["hlSwitch"]]==5)
##
text.corCI <- function(data) {
    xx<-subset(data,consistent==1)[,c("choice","hlSwitch")]
    set.seed(123)
    xx.b<-boot(xx,function(x,i) cor(x[i,])[1,2],bootSize)
    paste("$",round(cor(xx)[1,2],3),"$ (confidence interval $CI_{95}=[",paste(round(boot.ci(xx.b,type="basic")[["basic"]][4:5],3),collapse="\\penalty0 ,"),"])$")
}
##
bothTasks <- merge(EG[["onlineBLP"]],HL[["onlineBLP"]])
egHlcorCI <- text.corCI(bothTasks)
bothRN <- text.binomCI(with(subset(bothTasks,consistent==1),choice==3 & hlSwitch==5))
##
bothLabTasks <- merge(EG[["BLP"]],HL[["BLP"]])
egHllabcorCI <- text.corCI(bothLabTasks)
bothlabRN    <- text.binomCI(with(subset(bothLabTasks,consistent==1),choice==3 & hlSwitch==5))
##
ks.blp.test <- function(data,var="hlSwitch") 
    with(data,ks.test(data[grepl("BLP",type),var],data[!grepl("BLP",type),var]))[["p.value"]]
##
##ks.blp.test(subset(HL.df,consistent==1 & grepl("online",type)))
##ks.blp.test(subset(HL.df,consistent==1 & !grepl("online",type)))
@ 

\section{Introduction}

The \emph{Binary Lottery Procedure} (BLP henceforth) is, in theory, an
ingenious method of inducing risk neutrality of participants in experiments. If
an experiment requires that participants behave as if they are risk neutral,%
\footnote{%
Often, theories are to be tested under the auxiliary assumption that
participants are risk neutral.} one can pay them by lottery tickets rather than
directly with money. Each lottery ticket then gives participants an objective
probability of winning a high prize in a binary lottery. If participants satisfy
two axioms (monotonicity and the reduction of objective compound lotteries (ROCL),
axioms which are satisfied, in particular, for expected utility maximisers),%
\footnote{%
See \cite{selten1999money} for formal statements.} they should simply
maximise the probability of winning the high prize, in other words, they
should maximise the expected number of lottery tickets.

Since \cite{smith1961consistency} proposed and \cite{roth1979game}
implemented (and independently proposed) the BLP, many experimenters have
employed it in order to induce risk neutrality.\footnote{%
It was also discussed in various experimental textbooks %
\citep[e.g.][]{kagel1995handbook}, while \citet{berg2008performance}
specifically argue strongly for its merits.} 
%
However, already \citet{kahnemanTversky:79} show that human decision
makers do not always follow ROCL.
%
After \cite%
{selten1999money} found in an experiment that the BLP did not work at
all as intended, the use of the BLP by experimenters came to an
effective halt.\footnote{%
  See also \cite{loomes1998probabilities} where %
  it is also found that the BLP did not have the predicted effect.} %
Recently, there seems to be some kind of resurrection of the
method.\cite{harrison2013inducing} have re-examined the procedure and
found evidence that, at least, it moves risk preferences towards risk
neutrality. This has in turn inspired the use of its premise for
incentive compatible belief elicitation through the binarized scoring
rule
\citep[see][]{hossain2013binarized,schlag2013eliciting,harrison2014eliciting},
also discussed in \cite{schotter2014belief}. Given the conflicting
evidence, it seems appropriate to give the method another test.

We study the BLP in combination with two of the most popular
experimental methods to measure risk attitudes, the
\cite{holt2002risk} method and the \cite{eckel2002sex} method, which
was originally developed by \cite{binswanger1980attitudes}. These are
both standard risk preference elicitation tasks that are used in
numerous experimental papers.\footnote{%
  For recent surveys of risk preference elicitation see \cite%
  {charness2013experimental} and \cite{Holt2014}} If the BLP actually
succeeds in making participants behave as if they are risk neutral, we
should ideally observe only one type of choice: the choice that
maximises the expected number of lottery tickets.\footnote{%
  Of course, this presumes that participants are able to understand
  the tasks and choose the options that are best for them.} The short
answer is: this is not what we observe. In our main online treatment,
not even half of the participants (depending on the method between
\Sexpr{hlOnlineRN$mean} and \Sexpr{egOnlineRN$mean}) behave as if they
were risk neutral. The share of participants who behave as if they
were risk neutral across \emph{both} tasks is only
\Sexpr{bothRN[["mean"]]}.
%
Furthermore, comparing our main online treatment to a control
treatment, where the `standard' procedure is implemented for both the
\cite{holt2002risk} and the \cite{eckel2002sex} methods, we find no
significant difference in risk neutral choices.
  

We also compare the proportion of risk neutral choices in a lab-based
treatment with the BLP to other studies that have been implemented in
recent years utilizing the same subject pool in our laboratory. 
%
These studies implemented similar risk elicitation tasks as part of
their various experimental designs but with prizes rather than tokens
as is standard in the literature.
%
We can contrast the proportion of risk neutral choices while
implementing BLP (in our current data) and while not (comparison
studies).  The results suggest that implementing the BLP does not
result in a significant difference in the proportion of risk neutral
choices.

Using a structural model we find that the BLP moves participants'
behaviour, if at all, only slightly towards risk neutral choices.

\section{Experimental Design \label{sec:expdes}}


In this paper, we compare risky choices with and without implementing the BLP.
We use data from an online experiment with \Sexpr{nrow(HL[["onlineBLP"]])+nrow(HL[["onlineStd"]])} participants, from a lab experiment 
with \Sexpr{nrow(HL[["BLP"]])} participants, and from earlier comparison studies consisting of a total of 
\Sexpr{nPartCompareLab} participants (see Table \ref{tab:survey_studies} for details).
All participants were recruited from the same subject pool at the University
of Heidelberg.

The two risk elicitation tasks administered are a multiple price list
type task \citep{holt2002risk} and an \citet{eckel2002sex} type
task. Participants in the online and the lab experiments are asked to
respond to both risk elicitation tasks, with one of the tasks chosen
randomly for payment.\footnote{%
  This is done by a virtual coin toss in the online experiment and by
  an actual coin toss conducted by one of the participants in the lab
  experiment. Participants in the comparison studies responded to
  only one of the risk elicitation tasks. This procedure is incentive-compatible
  under fairly mild conditions. In particular, participants are assumed to respect
  first-order stochastic dominance, see \cite{Azrieli2019} and the
  literature cited there.}

In the online experiment, we have two treatments: one with the BLP
(\emph{onlineBLP}) and one with standard monetary payments (\emph{\onlineStd{}}).
The lab experiment is run with pen and paper using the BLP for all participants
(\emph{\labBLP{}}). Participants are recruited through SONA and hroot
\citep{Bock2014} for the online treatments and the lab experiment, respectively.
%
Participants receive a show-up fee of 2.50 Euro (\emph{\labBLP}: 5 Euro) and can earn an
additional 5 Euro depending on their decisions and the lottery realization.%
\footnote{%
  We ran a total of \Sexpr{nsession} sessions in the lab.  For
  the first two sessions of the data reported, participants had just
  completed an unrelated experiment and were asked if they were
  willing to spend few more minutes in the lab and participate in a
  new short experiment.  These participants did not receive an additional
  show-up fee.} Translated instructions are included in Appendix
\ref{sec:instructions}.

The binary lottery procedure is implemented as follows. Instead of
listing lotteries for monetary prizes, we let participants choose among
lotteries that pay out “tokens”. Each token corresponds to a
probability of 0.01 for winning the monetary prize of 5 Euro. The
instructions explicitly mention that the greater number of tokens
they earn, the higher the chance for winning a prize of 5 Euro. For
example, if a participant earns 72 tokens, the participant would have a probability of
0.72 to earn 5 Euro.\footnote{In the lab treatment
  this chance move is implemented by letting each participant throw two
  10-sided dice, one determining the tens and one determining the
  ones. If the participant rolls any number below or equal to 72, they
  would earn 5 Euro. In the online experiment the random number between
  0 and 99 is drawn by the computer.}

For our \EGtask{}, Table \ref{tabeg_lott} lists the 4
lotteries the participants have to choose from. Participants are asked to
choose their preferred one out of the four lotteries listed. Each lottery
has a 50\% chance to reward the participants with either the low or high
prize and this is determined by a coin flip at the end (virtual coin flip for
the online treatments, while real coin flip in the lab). In the standard 
procedure, where tokens are monetary prizes, choosing lotteries 1 or 2 is
indicative of risk
averse preferences as they entail lower (or even zero) variance, choosing
lottery 3 implies risk neutrality as it is the lottery that maximises
expected value and finally, choosing lottery 4 is indicative of risk seeking
behaviour as it is the lottery with the highest variance and a lower expected
value than lottery 3.

\begin{table}
\begin{center}
<<EGtable,results="asis">>=
print(xtable(rename(within(data.frame(cbind(Lottery=1:4,EG.payoffs[["BLP"]])),`Exp. value`<-(low+high)/2),c("low"="Tokens if coin shows Tails","high"="Tokens if coin shows Heads")),digits=0,align=c("c","c","c","c","c")),include.rownames=FALSE)
@ 
\end{center}
\caption{\cite{eckel2002sex} Lottery Task:  Participants choose one of the
lotteries 1-4}\label{tabeg_lott}%

\footnotesize Each lottery has equal chance of either outcome,
determined by a coin flip.  In 
\emph{\onlineStd{}}, the word “token” is replaced by “Taler” which is our 
experimental currency unit with an exchange rate of 20 Taler $=$ 1 Euro.
%
\end{table}%

For the \cite{holt2002risk} task, Table \ref{tab:hl_lott} displays the
choice list participants see. Participants have to choose
option A or B for each of the 10 situations listed. The last column
lists the difference in expected values of lotteries A and B. This is
not shown to participants. Any participant who wants to maximise expected
value would choose Lottery A for rows 1 through 4 and then switch to
Lottery B for rows 5-10.  For consistent decision makers we call the
first row for which a participant chose Lottery B the switch
point.\footnote{%
  Participants who switch more than once are coded as
  “inconsistent”. Among \Sexpr{nrow(HL[["BLP"]])+nrow(HL[["onlineBLP"]])+nrow(HL[["onlineStd"]])} participants in both our online and lab treatments, 
  we find \Sexpr{inconsistentPart+inconsistentOnline} that are inconsistent. If we
  instead code multiple switchers by the sum of the safe choices plus
  1 (similar to \citet[p.~1648]{holt2002risk}), the relative share of risk
  neutral choices slightly increases (see Table
  \ref{tab:risk_class}).} In the standard procedure, where tokens are monetary 
  prizes, 
participants with switch point of less than 5 would be classified as
risk seekers, those with a switch point of 5 would be classified as
risk neutral, and those with a switch point higher than 5 as risk
averse.\footnote{%
  Participants who always choose Lottery B have a switch point of 0. A
  switch point of 10 (always choose A) would imply a dominated choice
  for the last row.}

\begin{table}
  \begin{center}
  \footnotesize
  \def\ABcore#1#2#3#4#5{\begin{tabular}{@{}c@{}}#3 tokens of the die shows #1 \\\ifnum #5<10 #4 tokens if the die shows #2\fi\end{tabular}}
  \def\AA#1#2#3#4{#1 & \ABcore{#2}{#3}{40}{32}{#1} & $A$ or $B$ & \ABcore{#2}{#3}{77}{2}{#1} & $#4$ \\\hline}
\begin{tabular}{c|c|c|c|c} \hline
& Lottery $A$ & \begin{tabular}{@{}c@{}}Your\\choice\end{tabular} & Lottery $B$ & $\begin{array}{c}\text{EV}(A)-{}\\\text{EV}(B)\end{array}$ \\ \hline
<<holtLauryLotteriesBLP,results='asis'>>=
lRange <- function(i) ifelse(i<2,i,paste(1,i,sep="-"))
uRange <- function(i) ifelse(i>9,i,paste(i,10,sep="-"))
q<-sapply(1:10,function(i) cat(sprintf("\\AA{%d}{%s}{%s}{%.1f}",i,lRange(i),uRange(i+1),i*(4-7.7)+(10-i)*(3.2-.2))))
@ 
\end{tabular}  
\end{center}

\caption{\HLtask{}: Participants choose one of
  the lotteries $A$ or $B$ for each of the 10 possible
  situations}
\label{tab:hl_lott}

\footnotesize Note: One row is chosen for payment by use of a 10-sided
die. Suppose choice 3 is chosen and the participant chooses $A$. Then another
10-sided die determines whether they would get 40 tokens or 32 tokens. In
\emph{\onlineStd{}}, the word “token” is replaced by “Taler” which is our 
experimental currency unit with an exchange rate of $20$ Taler $=$ $1$ Euro. 
\end{table}%

For the comparison studies without the BLP, we
collect results and data from other recent studies that took place
in the same lab, which we refer to as \emph{\labStd}.
Given the anonymity of participants we cannot exclude
that some participated in more than one study. However, given
that the experiments were stretched over many years and given the
substantial turnover in the subject pool of more than 1000 participants,
the fraction of multiple participation is likely to be small.
%
These studies implemented similar risk elicitation
tasks but with prizes rather than tokens as is standard in the
literature. Table \ref{tab:survey_studies} lists the studies surveyed,
with information on which risk elicitation task each implemented and
the number of observations.
%
Table \ref{tab:EGpayoffs} in Appendix \ref{sec:payoffs} shows the payoffs
from the comparison studies.
%
The \HLtask{}s used in all studies are exactly the
same as the one in the current study up to a scaling factor. The
\cite{eckel2002sex} tasks are less comparable since each study used a different
number and kind of lotteries
which is unfortunately typical for \citeauthor{eckel2002sex} tasks in
the literature.\footnote{We chose the payoffs for our experiment to be
  somewhere in the middle of the comparison studies (see Figure
  \ref{fig:critR}).}

\begin{table}
  \begin{center}
<<summaryHL,results='asis',message=FALSE>>=
HL.all %$%
   table(type,consistent,useNA="ifany") %>%
   cbind %>%
   data.frame %>%
   tibble::rownames_to_column(var="type") %>%
   mutate(`Risk Task`="HL") %>%
   left_join(Literature) %>%
   rename(inconsistent=X0,consistent=X1) -> xx.hl
##
EG.df %$%
   table(type) %>%
   cbind %>%
   data.frame %>%
   tibble::rownames_to_column(var="type") %>%
   mutate(`Risk Task`="EG") %>%
   left_join(Literature) %>%
   rename(consistent=".") -> xx.eg
##
rbind.fill(xx.hl,xx.eg) %>%
    rename(Reference=ref,Comments=ltype,`Time of exp.`=exp) %>%
    select(Reference,"Time of exp.",type,"Risk Task",consistent,inconsistent) %>%
    arrange(sprintf("%02d-%02d-%s",`Risk Task`=="EG",!grepl("currentPaper",Reference),type)) %>%
    mutate(type=ifelse(type=="BLP","\\BLP",type)) %>%
    rename(Acronym=type,
           `\\begin{tabular}{c}Risk\\\\task\\end{tabular}`=`Risk Task`,
           `\\begin{tabular}{c}Cons.\\\\obs.\\end{tabular}`=consistent,
           `\\begin{tabular}{c}Incons.\\\\obs\\end{tabular}`=inconsistent) -> xx
##
xx %$%
    grepl("currentPaper",Reference) %>% 
    (function(x) which(diff(x)!=0)) %>%
    c(-1,0,.,nrow(xx)) -> hline
##
xx %>%
  xtable(align=c("l","p{18ex}","p{18ex}","c","c","c","c")) %>%
  print(include.rownames=FALSE,hline.after=hline)
@ 
%
\end{center}
\caption{Summary of the risk elicitation studies used.}
\footnotesize All participants were recruited from the same subject pool at the University of Heidelberg.
\label{tab:survey_studies}%

{\footnotesize {Note: EG stands for \cite{eckel2002sex} task and HL
    stands for \HLtask{}.} }%
\label{tab:NOBS}
\end{table}%

\section{Results}

\paragraph{Risk neutral choices}
When employing the BLP, participants in our experiment should
have a switch point of 5 in the \HLtask{} (HL henceforth) task and should
have chosen lottery 3 in the \cite{eckel2002sex} (EG henceforth) task.\footnote{%
  Under the assumptions of monotonicity and the reduction of objective
  compound lotteries.} In Table \ref{tab:risk_class} we report the
proportions of choices that are compatible with this payoff maximizing
prediction as “Risk neutral\textquotedblright.

\begin{table}
  \def\averse{\begin{tabular}[b]{@{}c@{}}Risk\\Av.\end{tabular}}
  \def\neutral{\begin{tabular}[b]{@{}c@{}}Risk\\Neut.\end{tabular}}
  \def\riskSeeking{\begin{tabular}[b]{@{}c@{}}Risk\\Seek.\end{tabular}}
\begin{center}
  %
<<prefStatistics,results='asis',message=FALSE>>=
types<-c("BLP","onlineBLP","onlineStd") ## we are only interested in "our" experiments
rbind.fill(EG) %>% 
    left_join(EG.payoffs.all) %>% 
    mutate(type=ifelse(type %in% types,type,"\\labStd")) %$% 
    table(type,pref) %>%
    data.frame %>%
    mutate(`Risk Task`="EG") -> EGtab
##
rbind.fill(HL) %>%
    mutate(type=ifelse(type %in% types,type,"\\labStd"),
           pref=cut(hlSwitch,c(-Inf,4,5,Inf),lab=c("riskSeeking","neutral","averse"))) -> HL.imed
HL.imed %$%
    table(type,pref) %>%
    data.frame %>%
    mutate(`Risk Task`="HL (all)") -> HL1tab
##
HL.imed %>%
    filter(consistent==1) %$%
    table(type,pref) %>%
    data.frame %>%
    mutate(`Risk Task`="HL (cons.)") -> HL2tab
##
rbind.fill(EGtab,HL1tab,HL2tab) %>%
#    mutate(type=factor(ifelse(type=="BLP","\\labBLP",as.character(type)))) %>%
    mutate(type=factor(ifelse(type=="BLP","\\labBLP",as.character(type)),
                       levels=c("onlineBLP","onlineStd","\\labBLP","\\labStd"))) %>%
    group_by(type,`Risk Task`) %>%
    mutate(relF=100*Freq/sum(Freq)) %>%
    tidyr::pivot_wider(id_cols=c("Risk Task","type"),names_from=pref,values_from=c("Freq","relF")) -> xx
xx[["Sum"]]<-apply(xx[,grep("^Freq",names(xx))],1,sum)
xx %>%
    arrange(`Risk Task`,`type`) %>%
    rename(Treatment=type) %>%
    rename_with(function(s) sub("Freq_","\\\\",s)) %>%
    rename_with(function(s) sub("relF_(.*)","\\\\\\1[\\\\%]",s)) %>%
    relocate(Sum,.after="Treatment") %>%
    xtable(.) %>%
    print(.,include.rownames=FALSE)
@ 
% 
\end{center}
\caption{Elicited Risk Preference Classifications.}\label{tab:risk_class}%
{\footnotesize {Note:} HL (cons.) are only the “consistent” choices in the \HLshort{}. HL (all) are all choices. We code multiple switchers in HL (all) by the number of times they choose Lottery A.}%
\end{table}%
%
In the \EGshort{}, in the \onlineBLP{} treatment only
\Sexpr{egOnlineRN$mean} (confidence interval \Sexpr{egOnlineRN$ci95}) of choices
can be classified as risk neutral. In the \labBLP{} treatment this percentage is 
even lower at \Sexpr{egRN$mean} (confidence interval \Sexpr{egRN$ci95}). 
In the \HLshort{} the proportion of risk neutral choices is even smaller, at 
\Sexpr{hlOnlineRN$mean} (confidence interval \Sexpr{hlOnlineRN$ci95}) for the \onlineBLP{} and \Sexpr{hlRN$mean} 
(confidence interval \Sexpr{hlRN$ci95}) for the \labBLP{}; certainly far away from the
ideal 100\%.  Furthermore, strictly speaking the BLP should make
participants risk neutral in both risk elicitation tasks
simultaneously. However, this works only 
%
for  \Sexpr{bothRN[["mean"]]} (confidence interval \Sexpr{bothRN[["ci95"]]}) of the participants in the \onlineBLP{} and 
for \Sexpr{bothlabRN[["mean"]]} (confidence interval \Sexpr{bothlabRN[["ci95"]]}) of the participants in the \labBLP{}.\footnote{%
  The switch point in the \HLshort{} and the chosen lottery in
  the \EGshort{} are however correlated with a coefficient of
  \Sexpr{egHlcorCI} in \onlineBLP{} and \Sexpr{egHllabcorCI} in \labBLP{}. 
 % 
  Notice that a negative correlation is to be expected. A higher
  switch point in HL implies higher risk aversion, while a lottery choice of
  higher value in EG implies lower risk aversion} 
%
Thus, it seems that the BLP clearly fails in letting all -- or even a
majority of -- participants behave as if they were risk neutral.

Given the different findings in the literature whether the BLP at
least shifts the distribution of preferences towards risk neutrality,
it is of course interesting to compare the share of risk-neutral
choices in studies with and without the BLP. For this purpose, we
report in Figure \ref{fig:RNchoices} the proportion of risk neutral
participants in our three treatments contrasted with the studies
outlined in Table \ref{tab:survey_studies} (\labStd). Contrasting the
two online treatments, we find that for both tasks, the HL and the
\EGshort{}, the number of risk neutral choices is higher with the BLP,
however only by a small amount. Comparing the \labBLP{} treatment with
\labStd, we still find an increase in the number of risk neutral
choices for the \EGshort{}. However, we find a small decrease for the
\HLshort{}.\footnote{%
  The LMK study has a much lower proportion of risk neutral
  participants than our data as well as the other two comparison
  studies (AOW and S). This can be because in LMK they implement a
  longer list of lotteries to choose from.  In LMK participants were
  choosing one out of 11 lottery options. Any noise in choices would
  then explain the lower percentage of risk neutral choices.}
%
\begin{figure}
<<riskNeutral,fig.height=3.5,fig.width=5>>=
eg.xx<-within(with(merge(rbind.fill(EG),EG.payoffs.all),aggregate(cbind(riskNeutral=pref=="neutral") ~ type,FUN=mean)),{
           EGHL<-"EG"
           type<-sub("online","onlineEG",type)
})
cx<-subset(HL.all,consistent==1)
hl.xx<-within(aggregate(cbind(riskNeutral=hlSwitch==5) ~ type,FUN=mean,data=cx),{
           EGHL<-"HL"})
xx<-rbind.fill(eg.xx,hl.xx)
xx<-within(xx,{
           online <- grepl("online",type)
           riskNeutralPercent<-riskNeutral*100
           })
xlim<-extendrange(xx$riskNeutralPercent,f=.3)
# generate four plots:
xx$type<-gsub("online|EG","\\\\,\\\\,",xx$type)
pp<-dlply(xx, ~ online + EGHL,function(x) {
    x$type<-with(x,reorder(type,riskNeutral + 10000*grepl("BLP",type) + 1000000*online + 10000*(EGHL=="EG")))
    stripText<-paste0(x[1,"EGHL"],"-",c("lab/other","online")[x[1,"online"]+1])
    dotplot(type ~ riskNeutralPercent | factor(stripText),xlab="",
            data=x,xlim=xlim,strip=TRUE,
            panel=function(x,y,...){
                panel.dotplot(x,y,...)
                labs <- sprintf("%.2f",x)
                panel.text(x,y,labs,adj=c(-.1,.5))
            })
    })
## draw the four plots:
yD<-.7;yd<-.5
plot(pp[[1]],position=c(0,0,.5,yD),more=TRUE)
plot(pp[[2]],position=c(.5,0,1,yD),more=TRUE)
plot(pp[[3]],position=c(0,yd,.5,1),more=TRUE)
plot(pp[[4]],position=c(.5,yd,1,1),more=FALSE)
@ 
\caption{Proportion of risk neutral choices for consistent decision makers.}
\label{fig:RNchoices}
\end{figure}
%
%% \begin{table}
%%   \centering
%% <<fisherTestsOddsx,results='asis',message=FALSE>>=
%% fisherOdds<-function (EGHL="EG",data,online=TRUE,neutral='pref!="neutral"') {
%%         data %>%
%%             subset(xor(online,!grepl("online",type))) %>%
%%             mutate(blp=grepl("BLP",type)) %$% 
%%             table(!blp,eval(parse(text=neutral))) %>%
%%             fisher.test() %$%
%%             c(EGHL,ifelse(online,"\\onlineBLP:\\onlineStd{}","\\labBLP:\\labStd"),round(estimate,3),
%%               ci=paste0("$[",paste(round(conf.int,3),collapse=","),"]$"))
%% }
%% #
%% t(cbind(
%%     sapply(FALSE:TRUE,function(o)
%%         fisherOdds(data=join(rbind.fill(EG),EG.payoffs.all),online=o)),
%%     sapply(FALSE:TRUE,function(o) 
%%         fisherOdds(EGHL='HL',subset(HL.all,consistent==1),online=o,"hlSwitch!=5")))) %>%
%%     data.frame %>% 
%%     dplyr::rename(`Risk Task`=V1,Comparison=V2,`Odds ratio`=odds.ratio,`$CI_{95}$`=ci)  %>%
%%     arrange(desc(Comparison)) %>% 
%%     xtable %>% 
%%     print(include.rownames=FALSE)
%% @ 
%% %
%% %
%%   \caption{Odds ratio (BLP vs.~standard procedure) of risk neutral choices for consistent decision makers}
%%   \label{tab:RNchoices}
%% \end{table}
%
The top part of Figure \ref{fig:RNchoices} shows results from the
online experiment.
%
%Table \ref{tab:RNchoices} shows the odds ratio
% (BLP versus standard procedure) to make risk neutral choices.
%
%% \ok{You add the following:}
%% \hd{Note that values
%% above 1 imply an increase, values below 1 imply a decrease and values exactly
%% equal to 1 imply no effect. We find that the BLP does imply a modest increase
%% of neutral choices for the \EGshort{} both online and in the lab, while only online for
%% the \HLshort{}.}

\paragraph{Distribution of choices in the \HLshort{}}
%
Figure \ref{fig:switchPointHLConsist} shows the frequency distribution
of switch points in the \HLshort{}. The top panels show
the BLP treatments. The bottom panels shows the standard treatments. On
the left we have the online treatments, while on the right we report the \labBLP{}
treatment which we compare with \labStd.

\begin{figure}  
<<figure3,fig.height=3.5,fig.width=5>>=
#
hlBreaks<-0:10+1/2
HL.all %>%
    subset(consistent==1) %>% 
    mutate(type=typeT1(type)) %>%
    group_by(type) %>%
    mutate(typeL = paste0(type[1],", $n=",length(type),"$")) %>% 
    ungroup %>%
    mutate(typeL=reorder(X=100*grepl("BLP",type)-1*grepl("online",type),typeL)) %>%
    histogram(~hlSwitch | typeL,data=.,
              breaks=hlBreaks,xlab="Switching point ($p_k$)") + 
    layer(panel.refline(v=5,col="red"))
@
\caption{Switching points in the \HLshort{} for consistent players.}
\label{fig:switchPointHLConsist}
\footnotesize The left part of the figure shows only the online treatments.
The right part shows the remaining treatments
Figure \ref{fig:switchPointHLConsistAll} shows the individual experiments.
The panel “\labStd” shows the pooled data from the \HLshort{} in \labStd{} (studies listed in Table
\protect \ref{tab:survey_studies}).

The risk neutral switching point is denoted by a vertical line.
\end{figure}
%
\begin{figure}  
<<figure3all,fig.height=3.5,fig.width=6>>=
histogram(~hlSwitch | typeT0(type,"labBLP|online"),as.table=TRUE,data=subset(HL.all,consistent==1),breaks=hlBreaks,xlab="Switching point") + layer(panel.refline(v=5,col="red"))
@
\caption{Switching points in the \HLshort{} for consistent players.}
\label{fig:switchPointHLConsistAll}
\footnotesize See Table \ref{tab:HLpayoffs} for payoffs.
The risk neutral switching point is denoted by a vertical line.
\end{figure}

Figure \ref{fig:switchPointHLConsistAll} shows the distribution for the
individual studies.
%
Comparing the two panels of Figure \ref{fig:switchPointHLConsist} it
seems pretty obvious that there is no substantial shift towards the
risk-neutral choice (indicated by the vertical line). A Kolmogorov-Smirnov test
shows that we cannot reject the hypothesis that the two distributions
are the same ($p=%
\Sexpr{round(ks.blp.test(subset(HL.df,consistent==1 & grepl("online",type))),3)}
%
$ for \onlineBLP{} vs.~\onlineStd{}, $p=%
\Sexpr{round(ks.blp.test(subset(HL.df,consistent==1 & !grepl("online",type))),3)}
%
$ for \labBLP vs.~\labStd).%
\footnote{This confirms the results of \citet{dickhaut2013high}.
  Although their study had a different intention, they also implement
  a BLP procedure in an \HLshort{} and find that the distribution of
  choices in their Low treatment is similar to standard procedure
  \HLshort{}s.}
% 
% 
\begin{figure}
<<figure3eg,fig.height=3,fig.width=6>>=
xx<-subset(rbind.fill(EG),grepl("online",type))
p1<-with(xx,histogram(~choice | type,as.table=TRUE,breaks=0:(max(choice))+1/2,xlab="Choice",layout=c(1,2)) + layer(panel.refline(v=3,col="red")) )
##
xx2<-subset(rbind.fill(EG),!grepl("online",type))
p2 <-with(xx2,histogram( ~ choice | typeT0(type,"labBLP"),
                        as.table=TRUE,breaks=0:(max(choice))+1/2,xlab="Choice",layout=c(2,2))) + layer(panel.refline(v=3,col="red"),packets=1:2) +  layer(panel.refline(v=c(10,11),col="red"),packets=c(3)) + layer(panel.refline(v=c(7,8),col="red"),packets=c(4))
plot(p1,position=c(0,0,.4,1),more=TRUE)
plot(p2,position=c(.4,0,1,1),more=FALSE)
@
\caption{Choices in the \EGshort{}.}
\label{fig:switchPointEG}
\footnotesize See Table \ref{tab:EGpayoffs} for payoffs.
%
The risk neutral choices are denoted by a vertical line.
\end{figure}

\paragraph{Distribution of choices in the \EGshort{}}

The left part of Figure \ref{fig:switchPointEG} shows choices for our
online implementation of the \EGshort{}.  As with the
\HLshort{}, we use a Kolmogorov-Smirnov test to compare
the BLP with the standard treatment.  We cannot reject the hypothesis
that the two distributions are the same 
($p=\Sexpr{round(ks.blp.test(subset(EG.df,grepl("online",type)),"choice"),3)}$).
%
The right part of Figure \ref{fig:switchPointEG} compares the \EGshort{} in the 
\labBLP{} treatment with \labStd.
%
Since payoffs for the \labStd{} implementation of the \EGshort{} are
all different (see Table \ref{tab:EGpayoffs}), we cannot compare the
distribution of choices between \labBLP{} and \labStd{} with the help
of a Kolmogorov-Smirnov test.

\section{Structural model}
\label{sec:struct}
%
\subsection{Model}

<<jagsIni,cache=TRUE>>=
runjags.options(silent.jags=FALSE,silent.runjags=FALSE,method="parallel",
                modules="glm",predraw.plots=FALSE)
initJags<-list()
initJags[[1]]<-list(.RNG.seed=1,.RNG.name="base::Mersenne-Twister")
initJags[[2]]<-list(.RNG.seed=2,.RNG.name="base::Super-Duper")
initJags[[3]]<-list(.RNG.seed=3,.RNG.name="base::Wichmann-Hill")
initJags[[4]]<-list(.RNG.seed=4,.RNG.name="lecuyer::RngStream")
@ 


\paragraph{Utility functions}
The data we use here elicits preferences for risk in different
ways. To make results comparable we translate the choices for each
decision maker $i$ into a parameter of a CRRA expected utility
function. This does not imply that decision makers would always follow
this utility function. The utility function is just a device to
facilitate comparison across different lotteries with different
payoffs and the different estimation methods that we implement.

\paragraph{Bayesian inference}
We have two major reasons to use Bayesian inference to present our
results: unbiasedness and transparency. We would like to have an
unbiased estimator for the non-linear structural model we estimate
below. We also want to transparently communicate our estimation
strategy and to allow other researchers to easily reproduce our
results.

\citet{armingerMuthen:98} provide an insightful discussion on the
shortcomings of ML, Pseudo ML, and weighted least squares in the
context of non-linear structural models. The Bayesian estimator
provides unbiased results even for small and medium sized samples,
even for estimates of parameters at the boundary of the parameter
space. Any ML estimator could deliver only biased results. 

Transparency is another important reason to use the Bayesian
framework: We are not aware of any standard tool to estimate this
problem.  We fear that any ML estimator could only be communicated as
a purpose-built, hard to comprehend and hard to replicate optimisation
problem.
%
Within the Bayesian framework we can transparently communicate our
models using the well known BUGS language.  We provide the data for
our experiment and our methods on-line.  Any reader who wants to
compare the Bayesian estimate of our non-linear structural model with
an alternative approach of his or her liking can easily perform this
comparison. 
%
Finally, the communication of results of the Bayesian estimation might
lead to less confusion than Frequentist Null Hypothesis Testing. In
this paper Bayesian methods help us to present results in a way that
is transparent and easy to understand.\footnote{On
  \url{https://www.kirchkamp.de/research/blp.html} we provide the
  Bayesian model in BUGS notation, the R commands, and the data.}

Bayesian inference has been used by experimental economists for a
number of tasks, e.g.~to study markets
\citep{Smith:64,Cipriani:2012,FarjamKirchkamp:2018}, risk
\citep{Harrison:90,engelKirchkamp:19}, learning \citep{El-Gamal:94},
auctions \citep{Kirchkamp_Reiss:2019} and to help with the design of
experiments \citep{El-Gamal:96}.\footnote{\citet{Vallois:2018} present
  an interesting discussion of the development of statistical methods
  in experimental economics.}  
%

%Bayes factors \citet{Bolton:2003}

\paragraph{Comparing lotteries}
In the \HLshort{}, each choice reflects one comparison of two
lotteries, $\Lott_A$ and $\Lott_B$.  For each \HLshort{} we include
here, payoffs are the same up to a scaling factor. Even if our
estimation approach introduced a bias, we should expect that
estimations from the different studies are affected by such a bias in
the same way. Below we will compare four different estimation
approaches. For the \HLshort{}, all approaches come to very similar
conclusions.

Our two online treatments of the \EGshort{} differ only in the payment
mechanism: BLP or standard. The \EGshort{} in our \labBLP{} treatment is,
however, less comparable with the other studies from the same lab
(\labStd).  Each of the studies implementing the \EGshort{} is based on
a different set of lotteries (see Figure \ref{fig:critR} and Table
\ref{tab:EGpayoffs}). Ideally, if the model for our estimation
represented the true data generating process, this difference among
lotteries should not matter. The estimator should still yield an
unbiased estimate. In practice, each model is only an approximation of
the truth and, hence, each estimation is only a possibly biased
approximation of the truth.  Different lotteries might be affected by
a bias in different ways. Nevertheless, we carried out all the
estimations we did for the online treatments to also compare \labBLP{}
with \labStd{} choices in the \EGshort{}.  Estimation results of this
last comparison are shown in Appendix \ref{sec:EGtables}.  These
results are, more or less, in line with estimation results for the
\HLshort{}. In this section we will focus on results of our online
treatments for both tasks. Additionally, we compare the \labBLP{} with
the \labStd{} choices for the \HLshort.

Each lottery $\Lott_k$ has two possible outcomes $j\in\{1,2\}$.  If,
in any of these comparisons of two lotteries, $\Lott_k$ and
$\Lott_{k'}$, lottery $\Lott_k$ is chosen, outcome $j$ realises with
probability $p_{jk}$, yielding a payment $x_{jk}$.  The utility from
choosing lottery $\Lott_k$ for decision maker $i$ with CRRA utility
function is then
%
\begin{equation}
  u_i(\Lott_k|r_i) = \sum_j p_{jk} \frac{x_{jk}^{1-r_i}-1}{1-r_i}
  \label{eq:CRRA}
\end{equation}
%
where $r_i$ is the coefficient of relative risk aversion. A risk neutral decision maker would be characterised by
$r_i=0$.  A more risk averse decision maker would have an $r_i>0$.
%
\begin{figure}
<<critR,fig.width=6,fig.height=2>>=
tol<-.Machine$double.eps^.9
uDiff<-function(r,x,pH=c(.5,.5)) (1-pH[1])*(x[1,1]^(1-r)-1)/(1-r)+pH[1]*(x[1,2]^(1-r)-1)/(1-r)- ((1-pH[2])*(x[2,1]    ^(1-r)-1)/(1-r)+pH[2]*(x[2,2]^(1-r)-1)/(1-r))
type2r<-function(type) {
    n<-nrow(EG.payoffs[[type]])
    xx<-data.frame(type=ifelse(type=="BLP"," EG",type),i=(2:n),r=sapply(1:(n-1),function(i) uniroot(uDiff,c(-10,10),x=EG.payoffs[[type]][c(i,i+1),],tol=tol)[["root"]]))
    within(xx,rM<-(r+c(r[-1],NA))/2)
}
EGnames<-names(EG.payoffs)
critR<-rbind.fill(lapply(EGnames[!grepl("online",EGnames)],type2r))
##
xx<-data.frame(type=" HL",i=1:9,r=sapply(seq(.1,.9,.1),function(p)
   uniroot(uDiff,c(-10,100),x=t(matrix(HL.payoffs[1,c("low1","high1","low2","high2")],c(2,2))),
     pH=c(p,p),tol=tol)[["root"]]))
critALL<-rbind.fill(critR,within(xx,rM<-c(r-.1)))
u<-unique(critALL$type)
critALL$type<-factor(critALL$type,levels=u[order(paste0(ifelse(grepl("BLP|online",u),"AA","XX"),u),decreasing=TRUE)])
rM.na<-which(is.na(critALL$rM))
critALL<-within(critALL,rM[rM.na]<-1.5*r[rM.na]-.5*r[rM.na-1])
##
dotplot(type ~ r,data=critALL,xlab="$r$") + layer(panel.refline(v=0)) + layer(with(critALL,panel.text(rM,type,i,cex=.5)))
@ 
%
\caption{Choices for decision makers with CRRA preferences.}
%
\footnotesize The figure shows the critical values of the coefficient
of relative risk aversion $r$ as given by \eqref{eq:CRRA} where a
decision maker is indifferent between two lotteries.  For the
\HLshort{}: Each of the ten choices corresponds to one dot and is
denoted with the index of that choice.  A decision maker with this
value of $r$ is, for that choice, indifferent between $A$ and $B$. For
the \EGshort{}s (including AOW, LMK and S):
Numbers denote the range of $r$ where this choice is
the preferred choice.
\label{fig:critR}
\end{figure}
%
Figure \ref{fig:critR} shows the critical coefficients of relative
risk aversion $r$ where a decision maker with CRRA preferences is
indifferent between two lotteries.

\paragraph{Random utility}
%
Faced with the choice between two lotteries, $\Lott_k$, and
$\Lott_{k'}$, we assume the probability to choose $\Lott_k$ follows a
logistic model:
%
\begin{equation}
  P(\Lott_{k} \succ_i \Lott_{k'}|r_i)= \LL\left(\left(u_i(\Lott_k|r_i) - u_i(\Lott_{k'}|r_i)\right) \cdot \sqrt{\tauLi}\right)
  \label{eq:logitBayes}
\end{equation}

Here $\LL$ is the logistic function.  Each decision maker is
characterised by two parameters: $r_i$ describes $i$'s preference
towards risk.  $\tauLi$ describes the precision of $i$'s preferences.
%
Equation \eqref{eq:logitBayes} is what \citet{BDM:63} call a Fechner
model.
%
A decision maker with a very large precision $\tauLi$ will appear
consistent and will almost always choose the lottery with the higher
utility.  A decision maker with a small precision $\tauLi$ will appear
less consistent.  A decision maker with a $\tauLi=0$ will choose both
lotteries, $\Lott_k$ and $\Lott_{k'}$, with the same probability.

We are mainly interested in the distribution of $r_i$ under different
elicitation procedures.  Since we use Bayesian inference, we have to
think about a prior. We use vague priors, i.e.~we assume that we have
almost no prior information at all. Nevertheless, to demonstrate the
robustness of the model we compare four different approaches, \normal,
\normalii, \robust, \randomPref:

\paragraph{Baseline (\normal)} As a standard case we assume that the
individual coefficient of relative risk aversion $r_i$ is drawn from a
normal distribution $r_i \sim N(\mu_r,\tauR)$ where $\mu_r$ is the
mean and $\tauR=1/\sigma_r$ is the precision of the Normal distribution.
%
We are interested in the population mean of this distribution
$\mu_r$. As a prior for $\mu_r$ we assume $\mu_r \sim N(0,.1)$,
i.e.~our prior expectation for the population mean is, on average,
risk neutral behaviour. The precision of this prior is only 0.1,
i.e. we allow that the prior population mean $\mu_r$ is with
probability 50\% between $\Sexpr{signif(qnorm(.25,sd=sqrt(10)),3)}$
and $\Sexpr{signif(qnorm(.75,sd=sqrt(10)),3)}$.

\paragraph{Changing the prior (\normalii{})} Since we use vague
priors, it does not matter much which mean we assume for the prior of
$\mu_r$. Still, \normalii{} is an attempt to convince the sceptical
reader that the prior for $\mu_r$ has (as long as it is a vague prior)
practically no influence. If all we knew was Table 3 in
\citet{holt2002risk}, we might expect an average coefficient of
relative risk aversion $\mu_r$ between 0.25 and 0.55, depending on the
size of the stakes and whether payoffs are hypothetical or real. While
\normal{} assumes (on average) a risk neutral prior, \normalii{}
assumes that $\mu_r \sim N(.5,.1)$, i.e.~\normalii{} assumes a priori
a quite risk averse population mean with an average coefficient of
relative risk aversion of $.5$. As in \normal{}, the precision of that
prior distribution is very small.  We still assume
$r_i \sim N(\mu_r,\tauR)$. Now the prior population average $\mu_r$ is
with probability 50\% between
$\Sexpr{signif(qnorm(.25,mean=.5,sd=sqrt(10)),3)}$ and
$\Sexpr{signif(qnorm(.75,mean=.5,sd=sqrt(10)),3)}$.
  
\paragraph{Robust estimation (\robust{})} Figures
\ref{fig:switchPointHLConsist} and \ref{fig:switchPointHLConsistAll}
suggest that, at least for the \HLshort{}, risk
aversion might include some outliers.
  %
An adaptive robust version of the model takes outliers into account,
assuming that $r_i$ is not necessarily normal but drawn from a $t$
distribution: $r_i \sim t(\mu_r,\tauR,\nu)$ \citep{lange:89} with
endogenous degrees of freedom $\nu$. For $\nu\to \infty$ this model
includes the normal model.  For $\nu < \infty$ outliers are
downweighted. As in \normal{}, we assume $\mu_r \sim N(0,.1)$.

\paragraph{Random preferences (\randomPref)}
%
Models \normal{}, \normalii{} and \robust{} are based on random
utility (Equation \eqref{eq:logitBayes}).  Random preferences are an
alternative to random utility.  An empirical comparison of models with
random preferences and random utility can be found, e.g., in
\citet{LMS:2002} and \citet{BIL:2012}.  Theoretical properties of
models with random utility and random preferences have recently been
discussed by \citet{wilcox:2011}, \citet{apesteguiaBallester:2018}, and
\citet{conteHey:2018}.  Although econometrically not always as
convenient as models with random utility, models with random
preferences seem to fit the data well and can be attractive from an
axiomatic viewpoint.
%
Therefore, we consider \randomPref{} as an alternative to \normal{},
\normalii{} and \robust{}. \randomPref{} is based on random
preferences as follows:
  %
\begin{equation}
  P(\Lott_{k} \succ_i \Lott_{k'}|r_i)= \int_{u_i(\Lott_k|\randomR_i) > u_i(\Lott_{k'}|\randomR_i)} \phi(r_i,\tauLi) \, d\randomR_i
  \label{eq:randomPref}
\end{equation}
%
As in \normal{}, \normalii{} and \robust{}, the parameter $r_i$
denotes the mean of the risk preference of decision maker $i$. The
random preference used for a specific comparison, $\randomR_i$, follows
a normal distribution with density $\phi$, mean $r_i$ and precision
$\tauLi$.

For specifications \normal{}, \normalii{}, \robust{} and \randomPref{}
we are primarily interested in the population parameter $\mu_r$ (the
population average coefficient of relative risk aversion $r_i$). We
also estimate the population precision of this preference $\tauR$,
i.e.~how much preferences in the population differ from each other.%
\footnote{The remaining priors are
  $\tauLi \sim \Gamma(.01,.01), \tauR \sim \Gamma(.01,.01)$,
  $\nu\sim \Gamma(1/30,1/30)$.  $\Gamma(\alpha,\beta)$ denotes the
  Gamma distribution with shape $\alpha$ and rate
  $\beta$. $N(\mu,\tau)$ is the normal distribution with mean $\mu$
  and precision $\tau$. $t(\mu,\tau,\nu)$ is the $t$-distribution with
  mean $\mu$, precision $\tau$ and $\nu$ degrees of freedom.}
%
<<critValuesForR>>=
## for the random utility model we need the critical value for r where decision makers are indifferent
## we also need the sign of the slope, so that either the interval to the left or to the right of the critical
## value counts
##
crra <- function (x,r) (x^(1-r)-1)/(1-r)
crra2 <- function (xvec,pH,r) (1-pH)*crra(xvec[1],r)+pH*crra(xvec[2],r) ## 2 prizes
crraDiff <- function (r,xvec,pH) crra2(xvec[1:2],pH,r) - crra2(xvec[3:4],pH,r) ## compare 2 prizes
## next determine whether interval for r is open upwards or downards, i.e. whether crra is increasing or decreasing
crraSlope <- function (r,xvec,pH,del=.1) (crraDiff(r=r+del,xvec=xvec,pH=pH)-crraDiff(r=r-del,xvec=xvec,pH=pH))/(2*del)<0
tol<-.Machine$double.eps^.9
lotts<-aggregate(sid ~ highProb + low + high + prefLow + prefHigh,data=rbind.fill(Lott),FUN=length)
critRR<-adply(subset(lotts,highProb<1),1,summarise,
      rI=try(uniroot(crraDiff,c(-10,10),xvec=c(low,high,prefLow,prefHigh),pH=highProb,tol=tol))[["root"]],
      rHigher=ifelse(crraSlope(r=rI,xvec=c(low,high,prefLow,prefHigh),pH=highProb),1,0))
critRR[["sid"]]<-NULL
@ 
<<genJagsModels>>=
## we use three models for JAGS.
## they all follow a similar structure, so we use the same skeleton here.
## we also prepare the CRRA utility function (or one and two prizes) as a string
genU <- function(x) paste("(",x,"[i]^(1-r[sid[i]])-1)/(1-r[sid[i]])",sep="")
genU2 <- function(x1,x2) paste("(1-highProb[i])*",genU(x1),"+highProb[i]*",genU(x2),sep="")
##
##  approach with tauL[k], tauR[p] ~ dgamma(m^2/d^2,m/d^2) does not perform too well with LMK and S.
##  tau ~ dexp(.01) is slightly faster and has lower psrf for LMK and S.
##
genModel <- function(robust=FALSE,randomPref=FALSE) {
    m <- "model {
    %likelihood%
    %df%
    for (k in 1:max(sid)) {
       tauL[k] ~ dexp(.01)
       sdL[k] <- 1/sqrt(tauL[k])     
       r[k] ~ %dr%
    }
    for (p in 1:max(pop)) {
       muR[p] ~ dnorm(muRP[1],muRP[2])
       tauR[p] ~ dexp(.01)
       sdR[p]<-1/sqrt(tauR[p])
    }
    for (p in 2:max(pop)) {
       dist[p-1]  <- abs(muR[1])-abs(muR[p])
       distR[p-1] <- dist[p-1]/sdR[1]
       pLen[p-1]  <- sum(pop==p) ## how many pops do we have?
       avrank[p-1]<- (sum(inprod(rank((r)^2),pop==p))-(pLen[p-1]^2+pLen[p-1])/2)/(pLen[p-1]*length(pop)-pLen[p-1]^2)
    }
}"
    param<-list(df="",dr="dnorm(muR[pop[k]],tauR[pop[k]])")
    param[["likelihood"]]<-paste("for (i in 1:length(low)) {
        choice[i] ~ dbern(p[i])
        Upref[i] <- ",genU2("prefLow","prefHigh"),"
        Usucc[i] <- ",genU2("low","high"),"
        logit(p[i]) <-  (Upref[i] - Usucc[i]) / sdL[sid[i]] ## Eq. (2)
    }",sep="")
    if (robust) {
        param[["df"]]<-"df ~ dexp(1/30)"
        param[["dr"]]<-"dt(muR[pop[k]],tauR[pop[k]],df)"
    }
    if(randomPref) 
        param[["likelihood"]]<-"for (i in 1:length(rI)) {
       myRR[i] ~ dnorm(r[sid[i]],tauL[sid[i]])
       rHigher[i] ~ dinterval(myRR[i],rI[i])
    }"
    for(var in names(param)) m<-gsub(paste("%",var,"%",sep=""),param[var],m)
    m
}
small.mod <- genModel()
robust.mod <- genModel(robust=TRUE)
rpref.mod <- genModel(randomPref=TRUE)
@ 
<<lott2sum>>=
### where is onlineBLP in LOtt ???
LottAll.df<-within(rbind.fill(Lott),EGHL<-factor(ifelse(is.na(consistent),"EG","HL")))
### here is a mistake, EG.online goes missing ^^^
LottEG.df<-subset(LottAll.df,EGHL=="EG")
LottHL.df<-subset(LottAll.df,EGHL=="HL")
##
LottConsist<-lapply(Lott,function(x) {
   if("consistent" %in% names(x)) return(subset(x,consistent==1))
   x
})
##
lott2sData <- function(Ln,pops="XXX",muRPrior=c(0,.1),randomPref=FALSE) {
    if (randomPref)
        Ln<-join(Ln,critRR,type="inner") ## add critical values to lotteries

   L.data <- as.list(within(Ln,{
         type<-as.numeric(factor(type));
         sid<-as.numeric(factor(sid));
         choice<-1;
   }))
   L.data[["muRP"]]<-muRPrior;
   ## L.data[["pop"]]<-aggregate(cbind(pop=(ifelse(type==pops,2,1))) ~ sid,data=Ln,FUN=mean)[["pop"]]
   L.data[["pop"]]<-aggregate(cbind(pop=(1+grepl(pops,type))) ~ sid,data=Ln,FUN=mean)[["pop"]]
   return(L.data)
}
##
lott2sum <- function(L,robust=FALSE,randomPref=FALSE,muRPrior=c(0,.1),save=FALSE,varname=NULL)  {
    if(is.null(varname)) {
        varname<-paste("jags",
                       ifelse(muRPrior[1]!=0,".1",""),
                       ifelse(identical(L,LottConsist),".Consist",""),
                       ifelse(robust,".rob",""),
                       ifelse(randomPref,".RP",""),
                       ".sum",
                       sep="")
    }
    filename<-paste0("mcmc/",varname,".Rdata")
    if(file.exists(filename))  { ## nothing to do
        load(filename)
        return(invisible(eval(parse(text=varname))))
    }
   jags.sum<-list()
   for(n in names(L)) {
      sData<-lott2sData(L[[n]],muRPrior=muRPrior,randomPref=randomPref)
      model <- genModel(robust=robust,randomPref=randomPref)
      ##sData<-lott2sData(head(Lott[["S"]],100))
      rj <- run.jags(model=model,data=sData,monitor=c("muR",'sdR'),
                     n.chains=4,inits=initJags)
      jags.sum[[n]]<-rj[["summary"]]
      jags.sum[[n]][["statistics"]]<-cbind(jags.sum[[n]][["statistics"]],
                                           seff=rj[["mcse"]][["sseff"]],
                                           psrf=rj[["psrf"]][["psrf"]][,1])
   }
   if(!save)
       return(invisible(jags.sum))
   eval(parse(text=paste(varname,"<-jags.sum")))
   eval(parse(text=paste0('save(',varname,',file="',filename,'")')))
   invisible(jags.sum)
}
##
lott2sumT <- function(...) {
    ## creates variables, saves them
    lott2sum(save=TRUE,...)
}
##
lott2jagsT <- function(dat="HL",online=NULL,robust=FALSE,randomPref=FALSE,muRPrior=c(0,.1),consist=FALSE,varname=NULL) {
    dat.df <- dat ## need this only for fake data
    if(dat=="HL") {
        if(consist)
            dat.df<-subset(LottHL.df,consistent==1)
        else
            dat.df<-LottHL.df
    }
    if(dat=="EG") 
        dat.df <- LottEG.df
    ##
    onl<-FALSE
    if(!is.null(online)) {
        dat.df <-subset(dat.df,xor(! online,grepl("online",type)))
        onl<-online
    }
    ##
    model <- genModel(robust=robust,randomPref=randomPref)
    sData <- lott2sData(dat.df,"BLP",muRPrior=muRPrior,randomPref=randomPref)
    if(is.null(varname)) {
        varname<-paste(dat,
                       ifelse(muRPrior[1]!=0,".1",""),
                       ifelse(onl,".online",""),
                       ifelse(consist,".Consist",""),
                       ifelse(robust,".rob",""),
                       ifelse(randomPref,".RP",""),
                       ".jags",
                       sep="")
    }
    filename<-paste0("mcmc/",varname,".Rdata")
    if(file.exists(filename))  { ## nothing to do
        load(filename)
        return(invisible(eval(parse(text=varname))))
    }
    monitor<-c("muR",'sdR',"dist","distR","avrank")
    if(robust)
        monitor<-c(monitor,"df")
    jags<-run.jags(model=model,data=sData,monitor=monitor,n.chains=4,inits=initJags)
    eval(parse(text=paste(varname,"<- jags")))
    eval(parse(text=paste0('save(',varname,',file="',filename,'")')))
    return(invisible(jags))
}
@ 
%##
%## Here we create all the means, CIs for means
%## this is needed for the figures
%## we will run extra regression to compare treatments below
%##
<<jagsSummaries,cache=FALSE,include=FALSE>>=
lott2sumT(Lott)
@ 
<<jagsSummaries.1,cache=FALSE,include=FALSE>>=
lott2sumT(Lott,muRPrior=c(.5,.1))
@ 
<<jagsSummaries.rob,cache=FALSE,include=FALSE>>=
lott2sumT(Lott,robust=TRUE)
@ 
<<jagsSummaries.ranPref,cache=FALSE,include=FALSE>>=
lott2sumT(Lott,randomPref=TRUE)


@ 
%
<<jagsConsistSummaries,cache=FALSE,include=FALSE>>=
lott2sumT(LottConsist)
@ 
<<jagsSummaries.1.Consist,cache=FALSE,include=FALSE>>=
lott2sumT(LottConsist,muRPrior=c(.5,.1))
@ 
<<jagsSummaries.Consist.rob,cache=FALSE,include=FALSE>>=
lott2sumT(LottConsist,robust=TRUE)
@ 
<<jagsSummaries.Consist.ranPref,cache=FALSE,include=FALSE>>=
lott2sumT(LottConsist,randomPref=TRUE)
@ 
%
<<jSum2seg>>=
jSum2seg <- function (j,j.consist=NULL,title=NULL,EGHL=NULL,ONLINE=NULL) {
    j2sum <- function(j,consist=FALSE) 
        within(rbind.fill(lapply(names(j),function(n) {
            xx<-data.frame(j[[n]][["quantiles"]])
            xx[["var"]]<-factor(rownames(xx))
            xx[["type"]]<-factor(n)
            xx[["online"]]<-grepl("online",n)
            xx[["eghl"]]<-ifelse(n %in% names(EG.payoffs),"EG",ifelse(consist,"HL-consist","HL"))
            if(!is.null(ONLINE))
                xx<-subset(xx,online==ONLINE)
            xx
        })),type<-reorder(type,grepl("BLP",type)*1000+(eghl!="EG")*10000+ifelse(var=="muR",X50.,0)))
    #
    jags.sum.df<-j2sum(j)
    if(!is.null(EGHL))
        jags.sum.df<-subset(jags.sum.df,eghl==EGHL)
    if(!is.null(j.consist))
        jags.sum.df<-rbind.fill(jags.sum.df,subset(j2sum(j.consist,consist=TRUE),eghl!="EG"))
    jags.sum.df<-within(jags.sum.df,eghl<-factor(eghl,levels=c("EG","HL-consist","HL")))
    if(!is.null(title))
        jags.sum.df[["eghl"]]<-factor(title[1])
    ##
    xlim<-extendrange(c(0,range(jags.sum.df[,1:5])))
    #if(HL) jags.sum.df<-subset(jags.sum.df,EGHL=="HL")
    jags.sum.df <- within(jags.sum.df,{
        levels(var)<-gsub("sdR","$\\\\sigma_r$",gsub("muR","$\\\\mu_r$",levels(var)))
        levels(type)<-gsub("\\.HL$"," ",levels(type))
        strip<-factor(paste0(eghl," - ",var))
    })
    rows<-length(unique(jags.sum.df[["strip"]]))/2
    ##
    segplot(type ~ X2.5. + X97.5. |   strip,xlim=xlim, layout=c(2,rows),
            scales=list(relation=list(y="free"),rot=0),
            data = jags.sum.df,
            draw.bands = FALSE, centers = X50., 
            segments.fun = panel.arrows, ends = "both", 
            angle = 90, length = 1, unit = "mm") + layer(panel.refline(v=0,col="red"))
}
@   
\begin{figure}
<<jagsPerExp.online,fig.width=5.5,fig.height=3>>=
load("mcmc/jags.sum.Rdata")
load("mcmc/jags.Consist.sum.Rdata")
jSum2seg(jags.sum,jags.Consist.sum,ONLINE=TRUE)
@ 
%
\caption{Population parameters for \onlineBLP{} and \onlineStd{} treatments (\normal{})}
\footnotesize The figure shows for the two treatments the
median value of population parameters $\mu_r$ and
$\sigma_r=1/\sqrt{\tauR}$ together with a 95\% credible interval. Risk
neutrality corresponds to $\mu_r=0$.
%
Tables \ref{tab:seffPsrfHL.2} and \ref{tab:seffPsrfHL.2.Consist} in
Appendix \ref{sec:HLtables} provide convergence diagnostics.
%
Figures \ref{fig:muSigmaHL.2} and \ref{fig:muSigmaHL.2.Consist} 
in Appendix \ref{sec:HLtables} show
results for the other treatments and the other priors for the \HLshort{}.
Figure \ref{fig:muSigmaEG.2} in Appendix \ref{sec:EGtables}
shows corresponding results for the \EGshort{}.
%
\label{fig:muSigmaPerExp.Online}
\end{figure}
%
%
<<BLP.EG,cache=FALSE,include=FALSE>>=
lott2jagsT("EG",online=TRUE)
lott2jagsT("EG",online=FALSE)
@ 
<<BLP.EG.1,cache=FALSE,include=FALSE>>=
lott2jagsT("EG",muRPrior=c(.5,.1),online=TRUE)
lott2jagsT("EG",muRPrior=c(.5,.1),online=FALSE)
@ 
<<BLP.EG.rob,cache=FALSE,include=FALSE>>=
lott2jagsT("EG",robust=TRUE,online=TRUE)
lott2jagsT("EG",robust=TRUE,online=FALSE)
@ 
<<BLP.EG.RP,cache=FALSE,include=FALSE>>=
lott2jagsT("EG",randomPref=TRUE,online=TRUE)
lott2jagsT("EG",randomPref=TRUE,online=FALSE)
@ 
%% <<BLP.EG.RP,cache=FALSE,include=FALSE>>=
%% lott2jagsT("EG",randomPref=TRUE)
%% with(LottEG.df,table(type))
%% lott2jagsT(subset(LottEG.df,type %in% c("BLP","LMK")),randomPref=TRUE,varname="bl.joerg")
%% load("mcmc/bl.joerg.Rdata")
%% lott2jagsT(subset(LottEG.df,type %in% c("BLP","LMK")),muRPrior=c(2,.1),randomPref=TRUE,varname="bl1.joerg")
%% load("mcmc/bl1.joerg.Rdata")
%% summary(bl.joerg)
%% summary(bl1.joerg)
%% lott2jagsT(subset(LottEG.df,type %in% c("BLP","S")),randomPref=TRUE,varname="bs.joerg")
%% load("mcmc/bs.joerg.Rdata")
%% lott2jagsT(subset(LottEG.df,type %in% c("BLP","S","LMK")),randomPref=TRUE,varname="bsl.joerg")
%% load("mcmc/bsl.joerg.Rdata")
%% lott2jagsT(subset(LottEG.df,type %in% c("BLP","S","LMK","AOW")),randomPref=TRUE,varname="bsla.joerg")
%% load("mcmc/bsla.joerg.Rdata")
%% summary(bl.joerg)
%% summary(bs.joerg)
%% summary(bsl.joerg)
%% summary(bsla.joerg)
%% lott2jagsT(subset(LottEG.df,type %in% c("BLP","AOW")),randomPref=TRUE,varname="ba.joerg")
%% load("mcmc/ba.joerg.Rdata")
%% summary(ba.joerg)
%% @ 
<<BLP.HL,cache=FALSE,include=FALSE>>=
lott2jagsT("HL",online=TRUE)
lott2jagsT("HL",online=FALSE)
@ 
<<BLP.HL.1,cache=FALSE,include=FALSE>>=
lott2jagsT("HL",muRPrior=c(.5,.1),online=TRUE)
lott2jagsT("HL",muRPrior=c(.5,.1),online=FALSE)
@ 
<<BLP.HL.rob,cache=FALSE,include=FALSE>>=
lott2jagsT("HL",robust=TRUE,online=TRUE)
lott2jagsT("HL",robust=TRUE,online=FALSE)
@ 
<<BLP.HL.RP,cache=FALSE,include=FALSE>>=
lott2jagsT("HL",randomPref=TRUE,online=TRUE)
lott2jagsT("HL",randomPref=TRUE,online=FALSE)
@ 
<<BLP.HL.consist,cache=FALSE,include=FALSE>>=
lott2jagsT("HL",consist=TRUE,online=TRUE)
lott2jagsT("HL",consist=TRUE,online=FALSE)
@ 
<<BLP.HL.1.consist,cache=FALSE,include=FALSE>>=
lott2jagsT("HL",consist=TRUE,muRPrior=c(.5,.1),online=TRUE)
lott2jagsT("HL",consist=TRUE,muRPrior=c(.5,.1),online=FALSE)
@ 
<<BLP.HL.consist.rob,cache=FALSE,include=FALSE>>=
lott2jagsT("HL",consist=TRUE,robust=TRUE,online=TRUE)
lott2jagsT("HL",consist=TRUE,robust=TRUE,online=FALSE)
@ 
<<BLP.HL.consist.RP,cache=FALSE,include=FALSE>>=
lott2jagsT("HL",consist=TRUE,randomPref=TRUE,online=TRUE)
lott2jagsT("HL",consist=TRUE,randomPref=TRUE,online=FALSE)
@ 
<<BLP.EG.load,cache=FALSE>>=
for(fn in list.files("mcmc",".*jags.Rdata",full.names=TRUE)) {
    load(fn)
    obname<-gsub("mcmc/|.Rdata","",fn)
    cmd<-paste(gsub(".jags",".mc.df",obname),"<-data.frame(suppressWarnings(as.mcmc(",obname,")))")
    eval(parse(text=cmd))
}
@ 
%
Figure \ref{fig:muSigmaPerExp.Online} shows estimation results for \normal{}.  
%
\footnote{Results for priors \normalii{}, \robust{} and
  for random preferences \randomPref{} are very similar and are shown
  in Figures \ref{fig:muSigmaHL.2} and \ref{fig:muSigmaHL.2.Consist}
  in Appendix \ref{sec:HLtables}. Figure \ref{fig:muSigmaEG.2} in
  Appendix \ref{sec:EGtables} shows estimation results for the
  \EGshort{}.
%
  Table \ref{tab:seffPsrfHL.2} in Appendix \ref{sec:HLtables} shows
  diagnostics for the MCMC sampler (effective sample size,
  \citealp[p.~287]{gelmanBDA:13}, and potential scale reduction
  factor, \citealp{gelmanRubin1992}) for \normal{}, \normalii{},
  \robust{}, and \randomPref{}.}
%
From this figure it is clear that the BLP does not achieve complete
risk neutrality.  For no procedure does the 95\% credible interval
contain $\mu_r=0$.  Instead, with the BLP the median value of $\mu_r$
is about
\Sexpr{signif(jags.sum[["BLP.HL"]][["quantiles"]]["muR","50%"],3)}
  for the \HLshort{}.

\subsection{The effect of the binary lottery procedure}
\label{sec:effect}

As we have seen in Figure \ref{fig:muSigmaPerExp.Online}, the binary lottery
procedure does not clearly differ from the standard procedure. Let us,
nevertheless, try to assess the size of the effect of the binary
lottery procedure.  To do this, we assume that the individual
parameter $r_i$ is drawn from $r_i \sim N(\mu^\blp_r,\tau^\blp_r)$ if
preferences are elicited with the binary lottery procedure and $r_i$
is drawn from $r_i \sim N(\mu^\other_r,\tau^\other_r)$ otherwise.

We will compare $\mu^\blp_r$ with $\mu^\other_r$ in Section
\ref{sec:avgEffect}.  We will also compare the distribution of the
different $r_i$ for BLP and \otherLong{} in Section \ref{sec:rankEffect}.

\subsubsection{The average effect on $\mu_r$} 
\label{sec:avgEffect} 
\paragraph{Absolute effect size} 
%
If the BLP procedure does what it is supposed to do, then we should
expect $\mu^\blp_r$ to be closer to $0$ than $\mu^\other_r$.  In our
sample the posterior for the average relative risk aversion $\mu_r$ is
positive almost always. Nevertheless, to be on the safe side, we
compare absolute values of $\mu^\blp_r$ and $\mu^\other_r$ as follows:
%
\begin{equation} %
  \Delta_r = |\mu^\other_r| - |\mu^\blp_r | 
\end{equation}
%
If the binary lottery procedure has no effect, $E[\Delta_r]$ should be
zero.  If in the binary lottery procedure decision makers choose in a
more risk neutral way, then $E[\Delta_r]$ should be positive.
% 
<<medCI,cache=FALSE>>=
medCI <- function(j,var,text=var) {
   zm<- j$summary$statistics[var,"Mean"]
   z<- j$summary$quantiles[var,]
   paste("posterior mean of $",text,sprintf("=%.5f$ (credible interval $\\text{CI}_{95}=[%.5f, %.5f]$)\\footnote{Effective sample size=%.0f, potential scale reduction factor=%.5f.}",zm,z["2.5%"],z["97.5%"],j[["mcse"]][["sseff"]][var],j[["psrf"]][["psrf"]][var,1]))
}
medCIT <- function(j,j.df,var,hyp=">0",var2=NULL) { ## table version
   zm<- j$summary$statistics[var,"Mean"]
   z<- j$summary$quantiles[var,]
   df="$\\infty$"
   if("df" %in% rownames(j$summary$quantiles))
      df=signif(j$summary$quantiles["df","50%"],3)
   t<-sprintf("$%.5f$ & ",zm);
   if(!is.null(var2))
       t<-paste(t,sprintf("$%.5f$ & ",j$summary$statistics[var2,"Mean"]))
   paste(t,sprintf("$[%.5f, %.5f]$ & $%s$ & $%.0f$ & $%.5f$ & %s",
           z["2.5%"],z["97.5%"],
           string.odds(odds(eval(parse(text=paste("j.df[[var]]",hyp))))),
           j[["mcse"]][["sseff"]][var],
           j[["psrf"]][["psrf"]][var,1],df))
}
@
%
%
\begin{table}
  \begin{center}
\begin{tabular}{cccccccc}
  \hline
\multicolumn{2}{r}{\begin{tabular}[t]{@{}c@{}}mean\\$\Delta_r=|\mu^\other_r| - |\mu^\blp_r |$\end{tabular}} & 
    \begin{tabular}[t]{@{}c@{}}mean\\$\strut\Delta_r/\strut\sigma_{r}^{\other}$\end{tabular}&  \begin{tabular}[t]{@{}c@{}}CI$_{95}$\\$\Delta_r$\end{tabular} & 
    \begin{tabular}[t]{@{}c@{}}odds\\ $\Delta_r>0$\end{tabular} & 
    \begin{tabular}[t]{@{}c@{}}effss\\$\Delta_r$\end{tabular} & 
   \begin{tabular}[t]{@{}c@{}} psrf\\$\Delta_r$\end{tabular} & 
   \begin{tabular}[t]{@{}c@{}}median \\$\nu$\end{tabular} \\\hline
  \multicolumn{6}{l}{\EGtask{}, online data}\\
   \normal    &\Sexpr{medCIT(EG.online.jags,EG.online.mc.df,'dist',var2='distR')} \\
   \normalii  &\Sexpr{medCIT(EG.1.online.jags,EG.1.online.mc.df,'dist',var2='distR')} \\
   \robust    &\Sexpr{medCIT(EG.online.rob.jags,EG.online.rob.mc.df,'dist',var2='distR')} \\
   \randomPref&\Sexpr{medCIT(EG.online.RP.jags,EG.online.RP.mc.df,'dist',var2='distR')} \\
  \multicolumn{6}{l}{\HLtask{}, online data}\\
   \normal    &\Sexpr{medCIT(HL.online.jags,HL.online.mc.df,'dist',var2='distR')} \\
   \normalii  &\Sexpr{medCIT(HL.1.online.jags,HL.1.online.mc.df,'dist',var2='distR')} \\
   \robust    &\Sexpr{medCIT(HL.online.rob.jags,HL.online.rob.mc.df,'dist',var2='distR')} \\
   \randomPref&\Sexpr{medCIT(HL.online.RP.jags,HL.online.RP.mc.df,'dist',var2='distR')} \\
  \multicolumn{6}{l}{\HLtask{}, online data, consistent only}\\
   \normal    &\Sexpr{medCIT(HL.online.Consist.jags,HL.online.Consist.mc.df,'dist',var2='distR')} \\
   \normalii  &\Sexpr{medCIT(HL.1.online.Consist.jags,HL.1.online.Consist.mc.df,'dist',var2='distR')} \\
   \robust    &\Sexpr{medCIT(HL.online.Consist.rob.jags,HL.online.Consist.rob.mc.df,'dist',var2='distR')} \\
   \randomPref&\Sexpr{medCIT(HL.online.Consist.RP.jags,HL.online.Consist.RP.mc.df,'dist',var2='distR')} \\
\end{tabular}
\end{center}
\caption{Average effect of the BLP procedure on the average coefficient of relative risk aversion $\mu_r$.}
%
\footnotesize $CI_{95}$ is the 95\%-credible interval
(equal-tailed). $\nu$ are the degrees of freedom of the
$t$-distribution for the robust model. 
%
To assess convergence of the MCMC sampler for $\Delta_r$, the table
provides effective sample size (effss) \citep[p.~287]{gelmanBDA:13}
and potential scale reduction factor (psrf) \citep{gelmanRubin1992}).
%
Table \ref{tab:avDelta} shows results
for the \HLshort{} when comparing \labBLP{} and \labStd.
%
Table \ref{tab:avDeltaEG} in Appendix \ref{sec:EGtables} shows results
for the \EGshort{} when comparing \labBLP{} and \labStd{}.
%
\label{tab:EG.online.avDelta}
\end{table}
%
Table \ref{tab:EG.online.avDelta} summarises estimation results for
$\Delta_r$ for the \onlineBLP{} and \onlineStd{} treatments. The
effect of the BLP procedure is already small for the \EGshort{} (for
\normal{} a reduction of
\Sexpr{round(summary(EG.online.jags)["dist","Mean"],3)} for
$\mu_r$). It is even smaller, depending on the model even negative,
for the \HLshort{}.
%
Table \ref{tab:avDelta} summarises estimation results for the
\HLshort{} when comparing \labBLP{} and \labStd.  We find that effect
sizes are even smaller than effect sizes for the online treatments.
Table \ref{tab:avDeltaEG} in Appendix \ref{sec:EGtables} shows results
for the \EGshort{}.


\paragraph{Relative effect size:}
%
To relate the average effect shown in Table \ref{tab:EG.online.avDelta} to the
different risk preferences in the population, the third column in
Table \ref{tab:EG.online.avDelta} shows the ratio $\Delta_r/\sigma_r^{\other}$.
%
We see that the effect of the BLP procedure on risk aversion is in any
case not larger than
%
\Sexpr{signif(summary(HL.online.rob.jags)["distR","Mean"],3)*100}\% of
the standard deviation of risk aversion in our sample.
%

\paragraph{Strength of evidence}
%
<<pVal,include=FALSE>>=
qualText<-c("only anecdotal","positive","strong","very strong") ## <- KassRaftery
qualOdds<-exp(c(0,1,3,5,Inf))
##qualText<-c("only anecdotal","moderate","strong","very strong","decisive") ## <- Jeff.
##qualOdds<-10^(c(0,.5,1,1.5,2,Inf))
qualOddsT<-sub("Inf","\\infty",signif(qualOdds,3),fixed=TRUE)
oddsText<-paste("odds${}\\in [",qualOddsT[1:4],":1,",qualOddsT[2:5],":1]$:",qualText,"evidence")
@ 
%
To interpret posterior odds whether $\Delta_r>0$, i.e.~whether BLP
leads to a reduction of the average population risk aversion at all,
we follow the terminology of \citet{kassRaftery95:bayes_factor}.%
\footnote{\citet{kassRaftery95:bayes_factor} suggest the following
  terminology: \Sexpr{paste(oddsText,collapse=", ")}.}  
%

For the \EGshort{}, the odds with prior \robust{} that $\Delta_r>0$ are
%
\Sexpr{string.odds(odds(EG.online.rob.mc.df[["dist"]]>0))}, i.e.~we have 
%
\Sexpr{int.odds(odds(EG.online.rob.mc.df[["dist"]]>0),'the average attitude towards risk with the BLP procedure is',c('closer to','farther away from'))} risk neutrality.
%
The odds are even smaller for the other priors (see Table \ref{tab:EG.online.avDelta}).
%
For the \HLshort{},
the odds with prior \robust{} that $\Delta_r>0$ are
%
\Sexpr{string.odds(odds(HL.online.rob.mc.df[["dist"]]>0))}, i.e.~we have
%
\Sexpr{int.odds(odds(HL.online.rob.mc.df[["dist"]]>0),'the average attitude towards risk with the BLP procedure is',c('closer to','farther away from'))} risk neutrality.
%
The odds are even smaller for the other priors (see Table \ref{tab:EG.online.avDelta}).

\begin{table}
  \begin{center}
\begin{tabular}{cccccccc}
  \hline
\multicolumn{2}{r}{\begin{tabular}[t]{@{}c@{}}mean\\$\Delta_r=|\mu^\other_r| - |\mu^\blp_r |$\end{tabular}} & 
    \begin{tabular}[t]{@{}c@{}}mean\\$\strut\Delta_r/\strut\sigma_{r}^{\other}$\end{tabular}&  \begin{tabular}[t]{@{}c@{}}CI$_{95}$\\$\Delta_r$\end{tabular} & 
    \begin{tabular}[t]{@{}c@{}}odds\\ $\Delta_r>0$\end{tabular} & 
    \begin{tabular}[t]{@{}c@{}}effss\\$\Delta_r$\end{tabular} & 
   \begin{tabular}[t]{@{}c@{}} psrf\\$\Delta_r$\end{tabular} & 
   \begin{tabular}[t]{@{}c@{}}median \\$\nu$\end{tabular} \\\hline
  \multicolumn{6}{l}{\HLtask{}, lab/other}\\
   \normal    &\Sexpr{medCIT(HL.jags,HL.mc.df,'dist',var2='distR')} \\
   \normalii  &\Sexpr{medCIT(HL.1.jags,HL.1.mc.df,'dist',var2='distR')} \\
   \robust    &\Sexpr{medCIT(HL.rob.jags,HL.rob.mc.df,'dist',var2='distR')} \\
   \randomPref&\Sexpr{medCIT(HL.RP.jags,HL.RP.mc.df,'dist',var2='distR')} \\
%
  \multicolumn{6}{l}{\HLtask{}, lab/other, consistent only}\\
   \normal    & \Sexpr{medCIT(HL.Consist.jags,HL.Consist.mc.df,'dist',var2='distR')} \\
   \normalii  & \Sexpr{medCIT(HL.1.Consist.jags,HL.1.Consist.mc.df,'dist',var2='distR')} \\
   \robust    & \Sexpr{medCIT(HL.Consist.rob.jags,HL.Consist.rob.mc.df,'dist',var2='distR')} \\
   \randomPref& \Sexpr{medCIT(HL.Consist.RP.jags,HL.Consist.RP.mc.df,'dist',var2='distR')} \\\hline
\end{tabular}
\end{center}
\caption{Average effect of the BLP procedure on the average coefficient of relative risk aversion $\mu_r$ comparing \labBLP{} with \labStd.}
%
\footnotesize $CI_{95}$ is the 95\%-credible interval
(equal-tailed). $\nu$ are the degrees of freedom of the
$t$-distribution for the robust model. 
%
To assess convergence of the MCMC sampler for $\Delta_r$, the table
provides effective sample size (effss) \citep[p.~287]{gelmanBDA:13}
and potential scale reduction factor (psrf) \citep{gelmanRubin1992}).
%
Table \ref{tab:avDeltaEG} in Appendix \ref{sec:EGtables} shows results
for the \EGshort{}.
%
\label{tab:avDelta}
\end{table}
%


%% \paragraph{Robust estimation (\robust{}):} Table \ref{tab:avDelta} compares
%% for each task the standard approach (\normal{}, where we assume that $\mu_r$
%% follows a normal distribution) with an adaptive robust approach (\robust{},
%% where we allow $\mu_r$ to be $t$ distributed with $\nu$ degrees of
%% freedom). 
%% %
%% For the \HLtask{} we find a small
%% $\median(\nu)=\Sexpr{signif(summary(HL.rob.jags)["df","Median"],3)}$,
%% i.e.~the model selects a shape of the $t$-distribution quite different
%% from a normal distribution. However, regardless which procedure we
%% use, standard (\normal{}) or robust (\robust{}), the estimated effect
%% of the BLP procedure for the \HLtask{} seems to be
%% small.

%% \paragraph{Random preferences (\randomPref{}):} 
%% %
%% In the model with random preferences (Equation \eqref{eq:randomPref})
%% we find for the \HLtask{} the BLP procedure reduces
%% relative risk aversion by only
%% $\Delta_r=\Sexpr{signif(summary(HL.RP.jags)["dist","Mean"],3)}$.


\subsubsection{The individual effect on $r_i$}
\label{sec:rankEffect}

We might not only care about effects on the average but also about the
effect on the individual.  After all, we cannot rule
%
out that a few participants find the BLP procedure hard to understand
but that these participants affect the average behaviour
substantially. The experimenter might prefer that a larger share of
participants gains from a procedure, even if a few participants
lose. Here we try to estimate the size of the population that gains
from the BLP procedure.
%
To better understand the effect on the individual, we call
$\rank(r_i^2)$ the rank of the individual distance of the actual risk
preference $r_i$ to risk neutrality ($r=0$). Each of our $n$
participants has a rank, denoted $\rank(r_i^2)$. Decision makers
closer to risk neutrality $r=0$ will have a small rank, those further
away will have a larger rank.

We might say that the binary lottery procedure performs well if
participants under this procedure have mainly small ranks (i.e.~have a
small distance to risk neutrality) while participants under the
standard procedure have larger ranks.  We use the following measure:
\begin{equation}
  \rho = \frac{\left(\sum_{i \in \blp} \rank\left(r_i^2\right) \right) - \Rlow}{\Rhigh - \Rlow}
  \label{eq:rho}
\end{equation}
%
where $\Rlow$ is the smallest possible sum of ranks $\blp$ could
obtain (i.e.~all individual decision makers with $\blp$ have a smaller
$r_i^2$ than the other decision makers) and $\Rhigh$ is the highest
possible sum of ranks (i.e.~all individual decision makers with $\blp$
have a larger $r_i^2$ than the other decision makers).

If the binary lottery procedure has no effect at all, then $\rho$
should be $1/2$. If the binary lottery works perfectly, i.e.~all
individuals with $\blp$ are closer to $r=0$ than all the others, then
$\rho$ should be $0$.
%
Estimation results are shown in Table \ref{tab:relRankRho.online} for
the online treatments and in Table \ref{tab:relRankRho} we contrast \labBLP{} and
\labStd.
%
\begin{table}
  \begin{center}
\begin{tabular}{ccccccc}\hline
\multicolumn{2}{r}{mean $\rho$} & CI$_{95}(\rho)$ & odds $(\rho<1/2)$ & effss$(\rho)$ & psrf$(\rho)$ & $\median(\nu)$\\\hline
  \multicolumn{6}{l}{\EGshort{}}\\
   \normal    & \Sexpr{medCIT(EG.online.jags,EG.online.mc.df,'avrank','<1/2')} \\
   \normalii  & \Sexpr{medCIT(EG.1.online.jags,EG.1.online.mc.df,'avrank','<1/2')} \\
   \robust    & \Sexpr{medCIT(EG.online.rob.jags,EG.online.rob.mc.df,'avrank','<1/2')} \\
   \randomPref& \Sexpr{medCIT(EG.online.RP.jags,EG.online.RP.mc.df,'avrank','<1/2')} \\
  \multicolumn{6}{l}{\HLshort{}}\\
   \normal    & \Sexpr{medCIT(HL.online.jags,HL.online.mc.df,'avrank','<1/2')} \\
   \normalii  & \Sexpr{medCIT(HL.1.online.jags,HL.1.online.mc.df,'avrank','<1/2')} \\
   \robust    & \Sexpr{medCIT(HL.online.rob.jags,HL.online.rob.mc.df,'avrank','<1/2')} \\
   \randomPref& \Sexpr{medCIT(HL.online.RP.jags,HL.online.RP.mc.df,'avrank','<1/2')} \\
%
  \multicolumn{6}{l}{\HLshort{}, consistent only}\\
   \normal    & \Sexpr{medCIT(HL.online.Consist.jags,HL.online.Consist.mc.df,'avrank','<1/2')} \\
   \normalii  & \Sexpr{medCIT(HL.1.online.Consist.jags,HL.1.online.Consist.mc.df,'avrank','<1/2')} \\
   \robust    & \Sexpr{medCIT(HL.online.Consist.rob.jags,HL.online.Consist.rob.mc.df,'avrank','<1/2')} \\
   \randomPref& \Sexpr{medCIT(HL.online.Consist.RP.jags,HL.online.Consist.RP.mc.df,'avrank','<1/2')} \\\hline
\end{tabular}
\end{center}
\caption{Relative rank $\rho$ of BLP procedure -- online experiments.}
%
\footnotesize 
%
Estimations for the lab version of the \HLtask{} are shown in Table
\ref{tab:relRankRho}.
%
Estimations for the comparison of \labBLP{} and \labStd{}
implementation of the \EGshort{} are shown in Appendix
\ref{sec:EGtables} in Table \ref{tab:relRankRhoEG}.
\label{tab:relRankRho.online}
\end{table}

\begin{table}
  \begin{center}
\begin{tabular}{ccccccc}\hline
\multicolumn{2}{r}{mean $\rho$} & CI$_{95}(\rho)$ & odds $(\rho<1/2)$ & effss$(\rho)$ & psrf$(\rho)$ & $\median(\nu)$\\\hline
  %% \multicolumn{6}{l}{\EGtask{}}\\
  %%  \normal    & \Sexpr{medCIT(EG.jags,EG.mc.df,'avrank','<1/2')} \\
  %%  \normalii  & \Sexpr{medCIT(EG.1.jags,EG.1.mc.df,'avrank','<1/2')} \\
  %%  \robust    & \Sexpr{medCIT(EG.rob.jags,EG.rob.mc.df,'avrank','<1/2')} \\
  %%  \randomPref& \Sexpr{medCIT(EG.RP.jags,EG.RP.mc.df,'avrank','<1/2')} \\
  \multicolumn{6}{l}{\HLshort{}}\\
   \normal    & \Sexpr{medCIT(HL.jags,HL.mc.df,'avrank','<1/2')} \\
   \normalii  & \Sexpr{medCIT(HL.1.jags,HL.1.mc.df,'avrank','<1/2')} \\
   \robust    & \Sexpr{medCIT(HL.rob.jags,HL.rob.mc.df,'avrank','<1/2')} \\
   \randomPref& \Sexpr{medCIT(HL.RP.jags,HL.RP.mc.df,'avrank','<1/2')} \\
%
  \multicolumn{6}{l}{\HLshort{}, consistent only}\\
   \normal    & \Sexpr{medCIT(HL.Consist.jags,HL.Consist.mc.df,'avrank','<1/2')} \\
   \normalii  & \Sexpr{medCIT(HL.1.Consist.jags,HL.1.Consist.mc.df,'avrank','<1/2')} \\
   \robust    & \Sexpr{medCIT(HL.Consist.rob.jags,HL.Consist.rob.mc.df,'avrank','<1/2')} \\
   \randomPref& \Sexpr{medCIT(HL.Consist.RP.jags,HL.Consist.RP.mc.df,'avrank','<1/2')} \\\hline
\end{tabular}
\end{center}
\caption{Relative rank $\rho$ of BLP procedure -- lab/other experiments.}
%
\footnotesize 
Estimations for the online version are shown in Table \ref{tab:relRankRho.online}.
%
Estimations for the comparison of \labBLP{} and \labStd{}
implementation of the \EGshort{} are shown in Appendix
\ref{sec:EGtables} in Table \ref{tab:relRankRhoEG}.
\label{tab:relRankRho}
\end{table}

For prior M1 and the \EGshort{} in the online treatments we find a
change from 0.5 to
%
\Sexpr{round(summary(EG.online.jags)["avrank","Median"],3)},
%
i.e.~an effect of 
%
\Sexpr{round(.50-summary(EG.online.jags)["avrank","Median"],3)}.
%
The effect itself might be small, but the odds that $\rho<1/2$ are
\Sexpr{string.odds(odds(EG.online.mc.df[["avrank"]]<1/2))}, i.e. we have
\Sexpr{int.odds(odds(EG.online.mc.df[["avrank"]]<1/2),'under the BLP
  procedure',c('indeed more','actually fewer'))} participants behave
in a more risk neutral way.

For the \HLshort{} in the online treatments, if we include consistent
and non-consistent observations, the effect is, actually, negative. If
we consider consistent observations only, then the BLP procedure
changes $\rho$ from 0.5 to
%
\Sexpr{round(summary(HL.online.Consist.jags)["avrank","Median"],3)},
i.e.~an effect
of \Sexpr{round(.50-summary(HL.online.Consist.jags)["avrank","Median"],3)}.
The odds that $\rho<1/2$ are
\Sexpr{string.odds(odds(HL.online.Consist.mc.df[["avrank"]]<1/2))}, i.e. we have
%
\Sexpr{int.odds(odds(HL.online.Consist.mc.df[["avrank"]]<1/2),'under the BLP procedure',c('indeed more','actually fewer'))} 
%
participants behave in a more risk neutral way.

Things look a bit better for the \HLshort{} if we consider the
comparison of \labBLP{} and \labStd. There the BLP reduces $\rho$ from
0.5 down to \Sexpr{round(summary(HL.jags)["avrank","Median"],3)},
i.e.~an effect of
\Sexpr{round(.50-summary(HL.jags)["avrank","Median"],3)}. This is a
small effect, but we can be rather certain that there is at least an
effect in the right direction.
%
For the \HLshort{} the odds that $\rho<1/2$ are
\Sexpr{string.odds(odds(HL.mc.df[["avrank"]]<1/2))}, i.e., we have
%
\Sexpr{int.odds(odds(HL.mc.df[["avrank"]]<1/2),'under the BLP
  procedure',c('indeed more','actually fewer'))} participants behave
in a more risk neutral way.

Results are very similar for alternative priors \normalii{} and
\robust{} and for the model with random preferences, \randomPref{}.

%--------------------------------------------------------------------------------

To summarise, our structural estimation suggests that for both the
\EGshort{} and the \HLshort{} there is a rather small effect.

\section{Conclusion}

We design and report a simple experiment where we test whether the
Binary Lottery Procedure induces participants to behave as if they are
risk neutral in the \citet{holt2002risk} and \cite{eckel2002sex}
tasks.  Namely, we ask participants to respond to an
\cite{eckel2002sex} type task as well as a \citet{holt2002risk} type
task. The only tweak to these procedures that we make is to have
participants choose across lotteries of tokens rather than prize
money, exactly as the Binary Lottery Procedure proposes. If the
procedure works as intended, we should observe all (or at least most)
participants choosing lotteries that maximise expected earnings and
thus all appear to be risk neutral agents. We compare choices in this
tweaked procedure of the two tasks with a standard procedure where
participants choose while faced with monetary prizes rather than
tokens. Furthermore, we use a structural model to formalize our
analysis on the efficacy of the Binary Lottery Procedure.

Putting together the results of the proportion of risk neutral agents,
both in terms of the modal response within our data and the comparison
with other studies should put one in serious doubt on whether BLP does
indeed work in practice. Far from the majority of participants are
found to be risk neutral and in fact we do not find large differences
in the occurrence of risk neutral preferences between our own data and
other comparison studies where similar risk elicitation procedures
were implemented but with -- as is standard -- prize money.
%
Given how the Binary Lottery Procedure can complicate tasks for
participants and can be tedious in implementation and as it
importantly appears to not work as hoped, it seems redundant for
experimenters to be utilizing it.
%
However, an experimenter who is already satisfied if participants
behave in an only slightly more risk neutral way (rather than fully
risk neutrally) might still prefer the BLP. For this case we have only
mildly encouraging evidence that shows that the BLP moves participants
in the right direction.

As a side result, our study provides further evidence that risk
preferences are a complex phenomenon and different risk elicitation
methods will not in general produce exactly the same results. Thus, in
applied studies it might be advisable to employ various methods to
obtain more robust results.

There may be, however, alternative methods for making participants
behave as if there were risk neutral and there is some evidence that
they work as intended. \cite{Kirchkamp2006} tell participants that
their earnings in an auction are determined by the average of their
payoffs from playing the auction multiple times (e.g. 50 times) with
the same bidding function. They then find that bidding functions are
much closer to the risk neutral equilibrium bids.  Similarly,
\cite{Niemeyer2019} let participants choose lotteries in a \HLtask{}
where the payoff is determined by the average result of many drawings
from the chosen lottery. They find that most participants behave as if
they were risk neutral.
%



\bibliographystyle{apalike}
\bibliography{blpbiblio.bib}

\clearpage
\appendix
\renewcommand{\bottomfraction}{0.95}
\renewcommand{\topfraction}{0.95}
\renewcommand{\textfraction}{0.95}
\section{Alternative priors and convergence}
%
\label{app:altPrior}

\subsection{Results for the \HLtask{}}
\label{sec:HLtables}

%--------------------------------------------------------------------------------

Figure \ref{fig:muSigmaPerExp.Online} in Section \ref{sec:effect} shows
population parameters for the online treatments if priors follow
\normal{}.
%
Figure \ref{fig:muSigmaHL.2} in Section \ref{sec:HLtables} extends
Figure \ref{fig:muSigmaPerExp.Online}, adding more treatments and more
priors (\normal, \normalii, \robust, and \randomPref).
%
Figure \ref{fig:muSigmaHL.2.Consist} does the same,  taking into
account only consistent decision makers.
%
Table \ref{tab:seffPsrfHL.2} shows diagnostics (effective sample size,
\citealp[p.~287]{gelmanBDA:13}, and potential scale reduction factor,
\citealp{gelmanRubin1992}) for the results shown in Figures
\ref{fig:muSigmaPerExp.Online},
\ref{fig:muSigmaHL.2}.
%
Table \ref{tab:seffPsrfHL.2.Consist} does the same for Figure
\ref{fig:muSigmaPerExp.Online} and 
\ref{fig:muSigmaHL.2.Consist}.


%
<<jSum2seg2>>=
jSum2seg2 <- function (allMod,EGHL="HL") {
    j2sum <- function(j,mod) 
        within(rbind.fill(lapply(names(j),function(n) {
            xx<-data.frame(j[[n]][["quantiles"]])
            xx[["var"]]<-factor(rownames(xx))
            xx[["type"]]<-factor(n)
            xx[["eghl"]]<-ifelse(n %in% names(EG.payoffs),"EG","HL")
            xx[["mod"]]<-factor(mod)
            xx
        })),type<-reorder(type,(type %in% c("BLP","BLP.HL"))*1000+(eghl!="EG")*10000+ifelse(var=="muR",X50.,0)))

    ## ,type<-reorder(type,(type %in% c("BLP","BLP.HL"))*1000+(eghl!="EG")*10000+ifelse(var=="muR",X50.,0))
    #
    jags.sum.df<-subset(rbind.fill(lapply(names(allMod),function(m) j2sum(allMod[[m]],mod=m))),eghl==EGHL)
    xlim<-extendrange(c(0,range(jags.sum.df[,1:5])))
    #if(HL) jags.sum.df<-subset(jags.sum.df,EGHL=="HL")
    levels(jags.sum.df$var)<-gsub("sdR","$\\\\sigma_r$",gsub("muR","$\\\\mu_r$",levels(jags.sum.df$var)))
    levels(jags.sum.df$type)<-gsub("^BLP","\\\\labBLP ",levels(jags.sum.df$type))
    levels(jags.sum.df$type)<-gsub("\\.HL$","",levels(jags.sum.df$type))
    segplot( type ~ X2.5. + X97.5. |   var + mod,xlim=xlim,as.table=TRUE,
            scales=list(relation=list(y="free"),rot=0),
            data = jags.sum.df,
            draw.bands = FALSE, centers = X50., 
            segments.fun = panel.arrows, ends = "both", 
            angle = 90, length = 1, unit = "mm") + layer(panel.refline(v=0,col="red"))
}
@   
\begin{figure}
<<jagsPerExp.HL,fig.width=5.5,fig.height=6.5>>=
load("mcmc/jags.sum.Rdata")
load("mcmc/jags.1.sum.Rdata")
load("mcmc/jags.rob.sum.Rdata")
load("mcmc/jags.RP.sum.Rdata")
allMod<-list(`\\normal`=jags.sum,
     `\\normalii`=jags.1.sum,
     `\\robust`=jags.rob.sum,
     `\\randomPref`=jags.RP.sum)
jSum2seg2(allMod,EGHL="HL")
@ 
%
\caption{Population parameters for the \HLtask{}.}
%
\footnotesize This figure extends Figure
\ref{fig:muSigmaPerExp.Online}.  This figure shows, based on all
decision makers, for each approach and for each procedure in the
\HLtask{} the median value of parameters $\mu_r$ and
$\sigma_r=1/\sqrt{\tauR}$ together with a 95\% credible interval.
%
Table \ref{tab:seffPsrfHL.2} shows convergence diagnostics.
%
\label{fig:muSigmaHL.2}
\end{figure}
%
\begin{figure}
<<jagsPerExp.HL.Consist,fig.width=5.5,fig.height=6.5>>=
load("mcmc/jags.Consist.sum.Rdata")
load("mcmc/jags.1.Consist.sum.Rdata")
load("mcmc/jags.Consist.rob.sum.Rdata")
load("mcmc/jags.Consist.RP.sum.Rdata")
allMod<-list(`\\normal`=jags.Consist.sum,
     `\\normalii`=jags.1.Consist.sum,
     `\\robust`=jags.Consist.rob.sum,
     `\\randomPref`=jags.Consist.RP.sum)
jSum2seg2(allMod,EGHL="HL")
@ 
%
\caption{Population parameters for the \HLtask{}, consistent only.}
\footnotesize This figure extends Figure \ref{fig:muSigmaPerExp.Online}.
This figure shows, based on only consistent decision makers, for
each approach and for each procedure in the \HLtask{}
the median value of parameters $\mu_r$ and $\sigma_r=1/\sqrt{\tauR}$
together with a 95\% credible interval.
%
Table \ref{tab:seffPsrfHL.2.Consist} shows convergence diagnostics.
%
\label{fig:muSigmaHL.2.Consist}
\end{figure}
%
<<j2effTab>>=
j2effTab<-function(j,EGHL="HL") {
    j2conf <- function(su,mod) {
        cc<-t(sapply(su,function(x) 
            c(t(x[["statistics"]][c("muR","sdR"),c("seff","psrf")]))))
        within(data.frame(cc),{
            approach<-paste(rownames(cc),mod)
            eghl<-ifelse(rownames(cc) %in% names(EG.payoffs),"EG","HL")
        })
    }
    cCo<-subset(rbind.fill(lapply(names(j),function(mod) j2conf(j[[mod]],mod))),eghl==EGHL)
    rownames(cCo)<-sub("\\.HL","",sub("^BLP","\\\\labBLP",cCo$approach))
    cCo$eghl<-NULL
    cCo$approach<-NULL
    colnames(cCo)<-c("effss","psrf","effss","psrf")
    print(xtable(cCo,digits=c(0,0,5,0,5)),hline.after=c(0,nrow(cCo)),add.to.row=list(pos=list(-1),command=("\\hline & \\multicolumn{2}{c}{$\\mu_r$} & \\multicolumn{2}{c}{$\\sigma_r$}\\\\")))
}
@     
%
\clearpage
%
\begin{table}
  \begin{center}
<<seffPsrf.HL,results='asis'>>=
allMod<-list(`\\normal`=jags.sum,
     `\\normalii`=jags.1.sum,
     `\\robust`=jags.rob.sum,
     `\\randomPref`=jags.RP.sum)

j2effTab(allMod,EGHL="HL")
@ 
\end{center}
\caption{Effective sample size and convergence for the  \HLtask{}.}
\label{tab:seffPsrfHL.2}
\footnotesize The table shows effective sample size (effss) and
potential scale reduction factor (psrf) for the estimation results
shown in Figures \ref{fig:muSigmaPerExp.Online} and \ref{fig:muSigmaHL.2}.
\end{table}
%
\begin{table}
  \begin{center}
<<seffPsrf.HL.consist,results='asis'>>=
allMod<-list(`\\normal`=jags.Consist.sum,
     `\\normalii`=jags.1.Consist.sum,
     `\\robust`=jags.Consist.rob.sum,
     `\\randomPref`=jags.Consist.RP.sum)
j2effTab(allMod,EGHL="HL")
@ 
\end{center}
\caption{Effective sample size and convergence  for the  \HLtask{} (consistent only).}
\label{tab:seffPsrfHL.2.Consist}
%
\footnotesize The table shows effective sample size (effss) and
potential scale reduction factor (psrf) for the estimation results
shown in Figures \ref{fig:muSigmaPerExp.Online} and
\ref{fig:muSigmaHL.2.Consist}.
\end{table}


%--------------------------------------------------------------------------------
\clearpage
\subsection{Results for the \EGtask{}}
\label{sec:EGtables}
%
%
In our estimations for the \HLtask{} we assumed that each choice
reflects one comparison of two lotteries, $\Lott_A$ and
$\Lott_B$. Similarly, we model choices in the \EGtask{} as a number of
binary comparisons. To decide that, e.g., $\Lott_3$ is better than
$\Lott_1$, $\Lott_2$ and $\Lott_4$, the decision maker makes three
comparisons: $\Lott_3 \succ \Lott_1$, $\Lott_3 \succ \Lott_2$, and
$\Lott_3 \succ \Lott_4$.
%
Figure \ref{fig:muSigmaPerExp.Online} in Section \ref{sec:struct}
shows population parameters for the online treatments.  Figure
\ref{fig:muSigmaEG.2} is an extension of Figure
\ref{fig:muSigmaPerExp.Online} providing credible intervals for the
\labBLP{} and \labStd{} versions of the \EGtask{} and for the
different estimation approaches \normal, \normalii, \robust, and
\randomPref.
%
Table \ref{tab:EG.online.avDelta} in Section \ref{sec:struct} shows
estimates for the effect of BLP on the average coefficient of relative
risk aversion $\mu_r$ for the online treatments. Table
\ref{tab:avDeltaEG} extends Table \ref{tab:EG.online.avDelta} and
shows estimation results for the \labBLP{} and \labStd.
%
Table \ref{tab:relRankRho.online} in Section \ref{sec:struct} shows
estimation of the relative rank $\rho$ for the online treatments.
Table \ref{tab:relRankRhoEG} is an extension of Table
\ref{tab:relRankRho.online} and show estimates for the \labBLP{} and
\labStd{} data.  Equivalent results for the \HLtask{} are shown in
Tables \ref{tab:avDelta} and \ref{tab:relRankRho}.
%
Table \ref{tab:seffPsrfEG.2} shows convergence diagnostics for Figure
\ref{fig:muSigmaEG.2}.
%
%--------------------------------------------------------------------------------
\begin{figure}
<<jagsPerExp.EG.Consist,fig.width=5.5,fig.height=5.7>>=
allMod<-list(`\\normal`=jags.sum,
     `\\normalii`=jags.1.sum,
     `\\robust`=jags.rob.sum,
     `\\randomPref`=jags.RP.sum)
jSum2seg2(allMod,EGHL="EG")
@ 
%
\caption{Population parameters for the \EGtask{}.}
\footnotesize 
This is an extended version of Figure \ref{fig:muSigmaPerExp.Online}.
The figure shows for each approach and for each
procedure in the \EGtask{} the median value of
parameters $\mu_r$ and $\sigma_r=1/\sqrt{\tauR}$ together with a 95\%
credible interval.
%
Table \ref{tab:seffPsrfEG.2} show convergence diagnostics.
%
\label{fig:muSigmaEG.2}
\end{figure}
%--------------------------------------------------------------------------------
%
\clearpage
%
\begin{table}
  \begin{center}
\begin{tabular}{cccccccc}
  \hline
\multicolumn{2}{r}{\begin{tabular}[t]{@{}c@{}}mean\\$\Delta_r=|\mu^\other_r| - |\mu^\blp_r |$\end{tabular}} & 
    \begin{tabular}[t]{@{}c@{}}mean\\$\strut\Delta_r/\strut\sigma_{r}^{\other}$\end{tabular}&  \begin{tabular}[t]{@{}c@{}}CI$_{95}$\\$\Delta_r$\end{tabular} & 
    \begin{tabular}[t]{@{}c@{}}odds\\ $\Delta_r>0$\end{tabular} & 
    \begin{tabular}[t]{@{}c@{}}effss\\$\Delta_r$\end{tabular} & 
   \begin{tabular}[t]{@{}c@{}} psrf\\$\Delta_r$\end{tabular} & 
   \begin{tabular}[t]{@{}c@{}}median \\$\nu$\end{tabular} \\\hline
  \multicolumn{6}{l}{\EGtask{}}\\
   \normal    & \Sexpr{medCIT(EG.jags,EG.mc.df,'dist',var2='distR')} \\
   \normalii  & \Sexpr{medCIT(EG.1.jags,EG.1.mc.df,'dist',var2='distR')} \\
   \robust    & \Sexpr{medCIT(EG.rob.jags,EG.rob.mc.df,'dist',var2='distR')} \\
   \randomPref& \Sexpr{medCIT(EG.RP.jags,EG.RP.mc.df,'dist',var2='distR')} \\
\end{tabular}
\end{center}
%
\caption{Average effect of the BLP procedure on the average
  coefficient of relative risk aversion $\mu_r$ for \EGtask{} in \labBLP{} and \labStd.}
%
\footnotesize Estimations for the online treatments are provided in Table \ref{tab:EG.online.avDelta}.
\label{tab:avDeltaEG}
\end{table}

\begin{table}
  \begin{center}
\begin{tabular}{ccccccc}\hline
\multicolumn{2}{r}{mean $\rho$} & CI$_{95}(\rho)$ & odds $(\rho<1/2)$ & effss$(\rho)$ & psrf$(\rho)$ & $\median(\nu)$\\\hline
  \multicolumn{6}{l}{\EGtask{}}\\
   \normal     & \Sexpr{medCIT(EG.jags,EG.mc.df,'avrank','<1/2')} \\
   \normalii   & \Sexpr{medCIT(EG.1.jags,EG.1.mc.df,'avrank','<1/2')} \\
   \robust     & \Sexpr{medCIT(EG.rob.jags,EG.rob.mc.df,'avrank','<1/2')} \\
   \randomPref & \Sexpr{medCIT(EG.RP.jags,EG.RP.mc.df,'avrank','<1/2')} \\
\end{tabular}
\end{center}
%
\caption{Relative rank $\rho$ of BLP procedure for the \EGtask{}
in \labBLP{} and \labStd.}
%
\footnotesize Table \ref{tab:relRankRho} shows results for the
\HLtask{}.
Table \ref{tab:relRankRho.online} shows results for the online treatments
\label{tab:relRankRhoEG}
\end{table}
%--------------------------------------------------------------------------------
%
\begin{table}
  \begin{center}
<<seffPsrf.EG,results='asis'>>=
allMod<-list(`\\normal`=jags.sum,
     `\\normalii`=jags.1.sum,
     `\\robust`=jags.rob.sum,
     `\\randomPref`=jags.RP.sum)

j2effTab(allMod,EGHL="EG")
@ 
\end{center}
\caption{Effective sample size and convergence for the \EGtask{}.}
\label{tab:seffPsrfEG.2}
\footnotesize The table shows effective sample size (effss) and
potential scale reduction factor (psrf) for the estimation results
shown in Figure \ref{fig:muSigmaEG.2}.
\end{table}

\clearpage
\section{Payoffs for the experiments}
\label{sec:payoffs}

Tables \ref{tabeg_lott} and \ref{tab:hl_lott} in Section
\ref{sec:expdes} show payoffs for our BLP treatments. Tables
\ref{tab:EGpayoffs} and \ref{tab:HLpayoffs} in Appendix
\ref{sec:payoffs} show payoffs for the standard procedure experiments.

For \labBLP{} treatment, the payment of participants was conducted as
follows. First, one participant in each session flipped a coin to
determine which task was the payoff relevant for everyone. Then each
individual participant came to the front of the lab and flipped coins
and/or rolled 10-sided dice to determine their payment. In addition to
the show-up fee, average pay from the lottery choice was about 2.50
Euro for about 20\ minutes. At the end there was a questionnaire where
we asked for participants' gender.

For the online treatments the random draws were done by the computer
and shown to participants immediately after they made their
decisions. Participants in these treatments were paid via bank
transfer.

\begin{table}[h]
  \begin{center}\footnotesize
  \def\TA#1{\begin{tabular}[t]{c}#1\end{tabular} & }
  \def\TN#1#2{\makebox[6ex][c]{\begin{tabular}[t]{|c|} *#1\\#2\end{tabular}}}
  \def\TT#1#2{\makebox[6ex][c]{\begin{tabular}[t]{c} #1\\#2\end{tabular}}}
  \begin{tabular}{cl}\hline
<<EG.payoff.table,results='asis'>>=
q<-by(EG.payoffs.all,EG.payoffs.all$type,function(x) {
    cat("\\TA{",x$type[1],"}")
    adply(x,1,function(x) cat(sprintf("\\%s{%g}{%g}",ifelse(x$pref=="neutral","TN","TT"),x$low,x$high)))
    cat("\\\\\\hline\n")
    })
@ 
    \end{tabular}
    \end{center}
%
\caption{Payoffs for the \EGtask{}.}
    \footnotesize Choices classified as “risk neutral” are marked with a *.
In \labBLP{} and \onlineBLP{} participants would obtain \emph{tokens}.
Each token had a probability of 1/100 to win 5€ (see Appendix \ref{sec:instructions} for the details).
In the other experiments the prize was in €.    
\label{tab:EGpayoffs}
\end{table}

\begin{table}[h]
  \begin{center}
  \footnotesize
<<holtLauryLotteries,results='asis'>>=
xx<-data.frame(t(sapply(1:10,function(i) c(sprintf("In %d out of 10 cases you earn 40 tokens / 2€,\\endgraf in %d out of 10 cases you earn 32 tokens 1.6€",i,10-i),
sprintf("In %d out of 10 cases you earn 77 tokens/ 3.85€,\\endgraf in %d out of 10 cases you earn 2 tokens / 0.1€",i,10-i)))))
names(xx)<-c("Lottery A","Lottery B")
print(xtable(xx,align=c("c","p{.45\\linewidth}","p{.45\\linewidth}")),include.rownames=FALSE,hline.after=seq(-1,10))
@ 
\end{center}
\caption{Payoffs for the \HLtask{}.}
\label{tab:HLpayoffs}
%
\footnotesize In the binary lottery procedure participants were
instructed that they would obtain \emph{tokens}.  Each token had a
probability of 1/100 to win 5€. (see Appendix \ref{sec:instructions}
for details) For RTV, DRR, PRS, and BHO the prize was 2.00€ or 1.60€
for lottery $A$ versus 3.85€ or 0.10€ for lottery $B$.  For DOV the
prize was three times as much: 6.00€ or 4.80€ for lottery $A$ versus
11.55€ or 0.30€ for lottery $B$.
\end{table}

\clearpage
\section{Instructions}
\label{sec:instructions}

%--------------------------------------------------------------------------------
[This is a translation of the original German instructions. In the \onlineStd{} treatment, [tokens] are “Taler”. In the \onlineBLP{} and \labBLP{} treatment, [tokens] are “tokens”.]

\paragraph{Welcome to the Experiment}
\def\BUTTON#1{\tikz[baseline=(X.base)]{\node (X) [fill=gray!20,draw=black!50,rounded corners=.5ex,very thick,drop shadow] {#1};}}
\def\INPUT{\tikz[baseline=(X.base)]{\node (X) [fill=blue!20,draw=blue!80] {\makebox[20ex][c]{\strut}};}}
\def\CURRENCY{[tokens]}
\def\ONLINE{[[\emph{The following information is shown only in \onlineBLP{} and \onlineStd:}]]}
\def\PAPER{[[\emph{The following information is shown only in \labBLP{}:}]]}
\def\onlyBLP{[[\emph{The following information is shown only in \onlineBLP{} and \labBLP:}]]}
\def\onlyStd{[[\emph{The following information is shown only in \onlineStd{}:}]]}
\def\ALL{[[\emph{The following information is shown in all treatments:}]]}
\def\onlineCond#1#2{\endgraf\noindent\begin{tabular}{|p{.473\linewidth}|p{.473\linewidth}|}
                      \emph{\onlineBLP{} and \onlineStd:}&\emph{\labBLP{}:}\\
                      #1 & #2
                    \end{tabular}\endgraf}
\def\iiiCond#1#2#3{\endgraf\noindent\begin{tabular}{|p{.306\linewidth}|p{.306\linewidth}|p{.306\linewidth}|}
                      \emph{\onlineBLP{}:} & \emph{\onlineStd:} &\emph{\labBLP{}:}\\
                      #1 & #2 & #3 \\
                    \end{tabular}\endgraf}
\def\blpCond#1#2{\endgraf\noindent\begin{tabular}{|p{.473\linewidth}|p{.473\linewidth}|}
                      \emph{\onlineBLP{} and \labBLP:}&\emph{\onlineStd{}:}\\
                      #1 & #2
                    \end{tabular}\endgraf}

\mbox{}

\ONLINE:

In this experiment we study your decisions. The experiment is carried
out jointly by the Universität Heidelberg and the
Friedrich-Schiller-Universität Jena.  During the experiment we elicit
data in Jena:

\begin{itemize}  
\item To make sure that you participate only once in the experiment
  you have received an invitation to the experiment from the
  Universität Heidelberg.
  
  In the next step we will ask for the email address. You can
  participate only once and only with this email address.

\item Name, town of residence and bank account number: You will
  receive your payment after the experiment from the Universität
  Heidelberg via SEPA transfer.  To be able to transfer the money, the
  Universität Heidelberg needs your name, your town of residence, the
  zip code of your town of residence and your bank account number
  (IBAN). We will ask for this information.
      
\item Decisions: We will then describe your choice situation. You will
  enter your decisions.
\end{itemize}
%
Your personal data and your choices will be transferred at least four
weeks after the experiment to the Universität Heidelberg. Immediately
thereafter your personal data will be deleted in Jena. For more
information on processing your data in Jena contact
Prof. Dr. Oliver Kirchkamp\footnote{Here, and for Prof.~Dr.~Jörg Oechssler, was a link to the respective homepage.}.

The administration of the Universität Heidelberg will transfer your
payment. Your personal data will be separated from your
decisions. Only your decisions will be used in our research. For more
information regarding the processing of your data in Heidelberg please
contact Prof. Dr. Jörg Oechssler.

If you agree with this procedure and if you want to participate in the
experiment, please click on “Agree”:

\begin{flushright}
\BUTTON{Don't Agree} \BUTTON{Agree}
\end{flushright}

To be able to pay you, the Universität Heidelberg needs your name,
your town of residence and your bank account number:

\begin{center}
\begin{tabular}{lc}
  Please enter your name here: & \INPUT \\
  Please enter your town of residence here: & \INPUT \\
  Please enter the ZIP code of your town of residence here: & \INPUT \\
  Please enter your IBAN here: & \INPUT \\
\end{tabular}
\end{center}
\begin{flushright}
\BUTTON{Continue}
\end{flushright}


\PAPER{}%--------------------

Please read these instructions carefully. Please do not talk to other
participants. Please turn off your mobile phone and leave it turned off
until the end of the experiment. If you have any questions, please raise
your hand, and someone will come over. All participants have received the
same instructions.

\ALL{}%--------------------

This experiment consists of two decision problems. One of the decision
problems will be chosen for payment in the end\ldots 
%
\onlineCond{by the computer with a probability of 50\%.}%
{by flipping a coin.} 

Hence, you should work through both parts carefully because both parts
can be relevant for your payoff.

Additionally to the payoff from the decision problem, each participant
receives\ldots
%
\onlineCond{2.5€ for participation.}{5€ for participation.}
%
\onlineCond{}{%
All random decisions of coin flips and dice rolls will be made at the end of
the experiment by either yourself or some other volunteer with fair and
genuine coins and dice.}

\paragraph{Decision problem 1}\mbox{}

\onlineCond{}{Decision problem 1 will be chosen for payoff if the flipped coin shows “Tails”.}

In this experiment you have to make a choice among 4 lotteries. 

\onlineCond{Each lottery has two possible outcomes, Heads or
  Tails. Both outcomes are equally probable (i.e.~both have a
  probability of 50\%.  At the end of the experiment the computer
  chooses randomly one of the outcomes, Head or Tails.}%
{Each lottery has two possible outcomes. The outcome will be decided
  by flipping a coin at the end of the experiment (of course, this is
  independent of the coin above).}

Depending on whether the coin comes up “heads” or “tails” you
can win a number of “[tokens]”.

For example, in lottery 2 you win 52 [tokens] if heads comes up and 28
[tokens] if tails comes up.

%
\iiiCond{Tokens will later give you the opportunity to win 5 Euro by
  the draw of a random number between 1 and 100. Each random number
  between, and including, 1 and 100 is equally likely to occur.
}
%
{Taler are converted into Euro at the end of the experiment. The
  exchange rate is 20 Taler for 1 Euro.}
%%
{Tokens will later give you the opportunity to win 5 Euro by the draw
  of a random number between 1 and 100. Each random number between,
  and including, 1 and 100 is equally likely to occur.  \endgraf In
  fact, you will be able to draw the two random numbers yourself by
  rolling two 10-sided dice.  The tokens give you the chance of
  winning the 5 Euro.}
%
\iiiCond{ The more points you earn, the greater your chance of winning
  5 Euro.  \endgraf In particular, if the random number is equal or
  less than the number of tokens you own, then you win 5 Euro. If the
  random number is higher, you win nothing.}%
%
{}
%%
{The more points you earn, the greater your chance of winning 5 Euro.
  \endgraf%
  In particular, if the random number generated by the dice is equal
  or less than the number of tokens you own, then you win 5 Euro.}
%
\iiiCond{For example, if you chose lottery 2 and tails comes up, you
  win 28 tokens.  If the random number is 28 or less, you win 5
  Euro. If the random number is higher than 28, you win nothing.}
%    
{For example, if you chose lottery 2 and tails comes up, you win 28
  Taler.  At the end these will be converted into
  \Sexpr{sprintf("%.2f",28/20)} Euro.}
%    
    {For example, if you chose lottery 2 and tails comes up, you win
      28 tokens.  If the random number is 28 or less, you win 5
      Euro. If the random number is higher than 28, you win nothing.}
    \endgraf

Now please choose one of the lotteries 1-4.

\begin{center}
<<tokenTableEG,results='asis'>>=
xx<-cbind(Lottery=1:nrow(EG.payoffs[["BLP"]]),(EG.payoffs[["BLP"]]),"\\square")
colnames(xx)[2]<-"\\begin{tabular}{c}Tokens if coin\\\\shows Heads\\end{tabular}"
colnames(xx)[3]<-"\\begin{tabular}{c}Tokens if coin\\\\shows Tails\\end{tabular}"
colnames(xx)[4]<-"\\begin{tabular}{c}Please choose exactly\\\\one lottery\\end{tabular}"
print(xtable(xx,align=c("c","c","c","c","c")),include.rownames=FALSE)
@ 
\end{center}


\paragraph{Decision problem 2}\mbox{}

\onlineCond{}{Decision problem 2 will be chosen for payoff if the flipped coin shows “Heads”.}

In this experiment you have to make a choice across 2 lotteries, A or B, in
10 different cases. Each lottery has the same structure: with some
probability, you receive a large amount of [tokens] and with the residual
probability, you will receive a smaller amount of [tokens]. 


\onlineCond{The outcome of each chosen lottery will determined randomly at the end of the experiment. 
  Each number, 1, 2, 3,\ldots 10, will be drawn by the computer with the same probability.
At the end of the experiment the computer will also determine which of the 10 choices will be the payoff relevant one.
\endgraf
For example, say that choice 3 was determined as payoff relevant and say that in the third row you chose
lottery A. If at the end a random number between 1 and 3 was drawn, you
receive 40 [tokens] and if a random number between 4 and 10 was drawn, you receive 32
[tokens].}%
{Which of the 10 choices will be the payoff relevant one will be decided by throwing a 10-sided die
at the end of the experiment. Further, the outcome of the
chosen decision will be decided by throwing a 10-sided die.
\endgraf
For example, say the 10-sided die rolls a 3 and in the third row you chose
lottery A. If now the 10-sided die rolls a number between 1 and 3, you
receive 40 [tokens] and if it rolls a number between 4 and 10, you receive 32
[tokens].
}

\iiiCond{Tokens will later give you the opportunity to win 5 Euro by the draw of a
random number between 1 and 100. Each random number between, and including,
1 and 100 is equally likely to occur.}{If you have won 40 Taler, these will be converted into 2
  Euro. If you have won 32 Taler, these will be converted into 1.60
  Euro. We still use the exchange rate of 20 Taler for one Euro.}{Tokens will later give you the opportunity to win 5 Euro by the draw of a
random number between 1 and 100. Each random number between, and including,
1 and 100 is equally likely to occur.}
%
\iiiCond{If the random number is equal or less than the number of tokens you own, then you win
  5 Euro. If the random number is larger, you win nothing. Hence, the more points you earn, the greater
  your chance of winning 5 Euro.}
%
{}
{%
  In fact, you will be able to draw the two random numbers yourself by rolling two 10-sided dice.
  The tokens give you the chance of winning the 5 Euro. The more points you earn, the greater
  your chance of winning 5 Euro. In particular, if the random number generated
  by the dice is equal or less than the number of tokens you own, then you win
  5 Euro.}
%
\onlineCond{Now please choose one of the lotteries A or B across the different cases
  below by clicking on your preferred lottery in all 10 cases.}
%
{%
Now please choose one of the lotteries A or B across the different
  cases below by underlining your preferred lottery in the middle, in
  all 10 cases.}
%

\def\HLL#1#2{#1 tokens if die shows #2}
\begin{center}
\begin{tabular}{|c|c|c|}\hline
Lottery A & Your choice & Lottery B \\ \hline
 & \begin{tabular}{@{}c@{}}(please [choose/\\underline] one\\lottery in each row)\end{tabular} & \\\hline
<<hlLotTable,results='asis'>>=
mRange <- function(x) {
  if(min(x)==max(x)) return(x);
  sprintf("%g-%g",min(x),max(x))
}
mPack <- function(x,pay) {
cat("\\begin{tabular}{@{}c@{}}\\HLL{",pay[1],"}{",mRange(1:x),"}\n")
if(x<10)
cat("\\\\\\HLL{",pay[2],"}{",mRange((x+1):10),"}\n")
cat("\\end{tabular}\n")
}
q<-lapply(1:10, function(x) {
   mPack(x,c(40,32))
   cat("& A or B &")
   mPack(x,c(77,2))
   cat("\\\\\\hline")
})
@ 
\end{tabular}
\end{center}

%--------------------------------------------------------------------------------
<<saveAll>>=
save.image("all.Rdata")
@ 
\end{document}
