METARET – a Meta Analysis of the External Validity of Risk Elicitation
Tasks
================
Paolo Crosetto
This version: June 2019

This project is about the **external validity** of **risk elicitation
tasks** (RETs) – i.e. their ability to predict self-reported or
real-world behavior.

This repository contains

  - **data** contributed from each of several *contributed papers* by
    experimental economists and social psychologists.
  - **code** to format each original dataset into a common format for
    later analysis
  - **results** in the form of plots and tables (*work in progress*)
  - **code** for an interactive shiny app that will give the users the
    possibility to explore the data by themselves (*completely TODO*)

### Contributed papers (list updates as papers are contributed)

  - Crosetto, Paolo, and Filippin, Antonio, *The Bomb Risk Elicitation
    Task*, JRU, 2013
    [paper](https://link.springer.com/article/10.1007/s11166-013-9170-z)
    [data](/Data/Crosetto_Filippin_Experimental_Economics_2016)
  - Crosetto, Paolo, and Filippin, Antonio, *A Theoretical and
    Experimental Appraisal of Four Risk ELicitation Methods*, ExEc, 2016
    [paper](https://link.springer.com/article/10.1007/s10683-015-9457-9)
    [data](/Data/Crosetto_Filippin_Journal_Risk_Uncertainty_2013/)

## First look at the results

As a first step, I compute the (Pearson) correlation of each RET to
(each of a series of) self-reported risk measures.

Each task is represented by a point estimate + confidence interval. Here
are the results of correlations between several tasks and:

  - the SOEP risk question
  - the DOSPERT scale and its subscales

The plots and analyses are updated for each new contributed paper.

![](README_files/figure-gfm/unnamed-chunk-1-1.png)<!-- -->
